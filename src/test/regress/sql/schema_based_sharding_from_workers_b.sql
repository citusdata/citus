SET client_min_messages TO WARNING;
SELECT 1 FROM citus_add_node('localhost', :master_port, groupid => 0);
SELECT 1 FROM master_set_node_property('localhost', :master_port, 'shouldhaveshards', true);

SET citus.next_shard_id TO 2090000;
SET citus.shard_count TO 32;
SET citus.shard_replication_factor TO 1;
SET client_min_messages TO WARNING;

CREATE SCHEMA regular_schema;

CREATE FUNCTION create_citus_local_with_data(table_name text)
RETURNS void
LANGUAGE plpgsql
AS $func$
BEGIN
    EXECUTE format('
        CREATE TABLE regular_schema.%I (
            col_1 text,
            col_2 int,
            col_3 bigint GENERATED BY DEFAULT AS IDENTITY (START WITH 1000 INCREMENT BY 1000),
            col_4 timestamp,
            col_5 int,
            col_6 bigint GENERATED ALWAYS as (col_5 * 7) stored,
            col_7 numeric,
            col_8 text GENERATED ALWAYS as (col_1 || ''_dummy'') stored,
            col_9 bigint GENERATED ALWAYS AS IDENTITY (START WITH 100 INCREMENT BY 100)
        );', table_name);

    EXECUTE format('
        INSERT INTO regular_schema.%I (col_1, col_2, col_4, col_5, col_7)
        SELECT
            i::text, -- col_1
            i + 42, -- col_2
            ''2026-01-01 00:00:00''::timestamp + (i || '' seconds'')::interval, -- col_4
            i * 3, -- col_5
            (i * 1.5)::numeric -- col_7
        FROM generate_series(1, 1000) AS i;', table_name);

    EXECUTE format('
        INSERT INTO regular_schema.%I (col_1, col_2, col_3, col_4, col_5, col_7)
        OVERRIDING SYSTEM VALUE
        SELECT
            i::text, -- col_1
            i + 42, -- col_2
            1000 + i, -- col_3
            ''2026-01-01 00:00:00''::timestamp + (i || '' seconds'')::interval, -- col_4
            i * 3, -- col_5
            (i * 1.5)::numeric -- col_7
        FROM generate_series(1001, 2000) AS i;', table_name);

    EXECUTE format('
        SELECT citus_add_local_table_to_metadata(''regular_schema.%I'');', table_name);

    EXECUTE format('
        ALTER TABLE regular_schema.%I DROP COLUMN col_2;', table_name);

    EXECUTE format('
        ALTER TABLE regular_schema.%I DROP COLUMN col_7;', table_name);

    EXECUTE format('
            ALTER TABLE regular_schema.%I ADD COLUMN col_10 bigint DEFAULT -197;', table_name);
END;
$func$;

SELECT create_citus_local_with_data('citus_local_1');
SELECT create_citus_local_with_data('citus_local_2');
SELECT create_citus_local_with_data('citus_local_3');

SELECT create_citus_local_with_data('citus_local_4');
SELECT create_citus_local_with_data('citus_local_5');
SELECT create_citus_local_with_data('citus_local_6');

SELECT * INTO regular_schema.old_data_coordinator FROM regular_schema.citus_local_4;

SET citus.enable_schema_based_sharding TO ON;

CREATE SCHEMA tenant_4;
CREATE SCHEMA tenant_5;
CREATE SCHEMA tenant_6;

SET citus.enable_schema_based_sharding TO OFF;

-- Verify data consistency after moving to a distributed schema.
--
-- Repeat this for three different schemas to test copying data
-- i) to shards on different workers and ii) to a shard on the
-- coordinator, i.e., this node.
--
-- First, test this within a transaction block (and rollback) and then
-- outside of a transaction block.
BEGIN;
    ALTER TABLE regular_schema.citus_local_4 SET SCHEMA tenant_4;
    SELECT COUNT(*) = 0 FROM (
        (TABLE tenant_4.citus_local_4) EXCEPT (TABLE regular_schema.old_data_coordinator)
        UNION
        (TABLE regular_schema.old_data_coordinator EXCEPT TABLE tenant_4.citus_local_4)
    );
ROLLBACK;

ALTER TABLE regular_schema.citus_local_4 SET SCHEMA tenant_4;
SELECT COUNT(*) = 0 FROM (
    (TABLE tenant_4.citus_local_4) EXCEPT (TABLE regular_schema.old_data_coordinator)
    UNION
    (TABLE regular_schema.old_data_coordinator EXCEPT TABLE tenant_4.citus_local_4)
);

BEGIN;
    ALTER TABLE regular_schema.citus_local_5 SET SCHEMA tenant_5;
    SELECT COUNT(*) = 0 FROM (
        (TABLE tenant_5.citus_local_5) EXCEPT (TABLE regular_schema.old_data_coordinator)
        UNION
        (TABLE regular_schema.old_data_coordinator EXCEPT TABLE tenant_5.citus_local_5)
    );
ROLLBACK;

ALTER TABLE regular_schema.citus_local_5 SET SCHEMA tenant_5;
SELECT COUNT(*) = 0 FROM (
    (TABLE tenant_5.citus_local_5) EXCEPT (TABLE regular_schema.old_data_coordinator)
    UNION
    (TABLE regular_schema.old_data_coordinator EXCEPT TABLE tenant_5.citus_local_5)
);

BEGIN;
    ALTER TABLE regular_schema.citus_local_6 SET SCHEMA tenant_6;
    SELECT COUNT(*) = 0 FROM (
        (TABLE tenant_6.citus_local_6) EXCEPT (TABLE regular_schema.old_data_coordinator)
        UNION
        (TABLE regular_schema.old_data_coordinator EXCEPT TABLE tenant_6.citus_local_6)
    );
ROLLBACK;

ALTER TABLE regular_schema.citus_local_6 SET SCHEMA tenant_6;
SELECT COUNT(*) = 0 FROM (
    (TABLE tenant_6.citus_local_6) EXCEPT (TABLE regular_schema.old_data_coordinator)
    UNION
    (TABLE regular_schema.old_data_coordinator EXCEPT TABLE tenant_6.citus_local_6)
);

CREATE TABLE regular_schema.reference_table (id bigint PRIMARY KEY);
SELECT create_reference_table('regular_schema.reference_table');

\c - - - :worker_1_port

-- When creating a tenant table from workers, we always fetch the next shard id
-- and placement id from the coordinator because we never sync those sequences to
-- workers. For this reason, along this test file, we always set the next shard id
-- on the coordinator when needed, rather than setting it on the current worker node.
-- At the end of the test file, we reset it back fwiw.
SELECT 1 FROM run_command_on_coordinator($$ALTER SYSTEM SET citus.next_shard_id TO 2091000;$$);
SELECT 1 FROM run_command_on_coordinator($$SELECT pg_reload_conf();$$);
SELECT pg_sleep(0.1); -- make sure that the GUC change is applied

SET citus.shard_count TO 32;
SET citus.shard_replication_factor TO 1;
SET client_min_messages TO WARNING;

SELECT * INTO regular_schema.old_data_worker FROM regular_schema.citus_local_1;

SET citus.enable_schema_based_sharding TO ON;

CREATE SCHEMA tenant_1;
CREATE SCHEMA tenant_2;
CREATE SCHEMA tenant_3;

-- Verify data consistency after moving to a distributed schema.
--
-- Repeat this for three different schemas to test copying data
-- i) to a shard on this worker, ii) to a shard on another worker, and
-- iii) to a shard on the coordinator.
--
-- First, test this within a transaction block (and rollback) and then
-- outside of a transaction block.
BEGIN;
    -- lock the table early in the transaction to make sure we don't break in that case
    LOCK TABLE regular_schema.citus_local_1 IN ACCESS EXCLUSIVE MODE;

    ALTER TABLE regular_schema.citus_local_1 SET SCHEMA tenant_1;
    SELECT COUNT(*) = 0 FROM (
        (TABLE tenant_1.citus_local_1) EXCEPT (TABLE regular_schema.old_data_worker)
        UNION
        (TABLE regular_schema.old_data_worker EXCEPT TABLE tenant_1.citus_local_1)
    );
ROLLBACK;

ALTER TABLE regular_schema.citus_local_1 SET SCHEMA tenant_1;
SELECT COUNT(*) = 0 FROM (
    (TABLE tenant_1.citus_local_1) EXCEPT (TABLE regular_schema.old_data_worker)
    UNION
    (TABLE regular_schema.old_data_worker EXCEPT TABLE tenant_1.citus_local_1)
);

BEGIN;
    ALTER TABLE regular_schema.citus_local_2 SET SCHEMA tenant_2;
    SELECT COUNT(*) = 0 FROM (
        (TABLE tenant_2.citus_local_2) EXCEPT (TABLE regular_schema.old_data_worker)
        UNION
        (TABLE regular_schema.old_data_worker EXCEPT TABLE tenant_2.citus_local_2)
    );
ROLLBACK;

ALTER TABLE regular_schema.citus_local_2 SET SCHEMA tenant_2;
SELECT COUNT(*) = 0 FROM (
    (TABLE tenant_2.citus_local_2) EXCEPT (TABLE regular_schema.old_data_worker)
    UNION
    (TABLE regular_schema.old_data_worker EXCEPT TABLE tenant_2.citus_local_2)
);

BEGIN;
    ALTER TABLE regular_schema.citus_local_3 SET SCHEMA tenant_3;
    SELECT COUNT(*) = 0 FROM (
        (TABLE tenant_3.citus_local_3) EXCEPT (TABLE regular_schema.old_data_worker)
        UNION
        (TABLE regular_schema.old_data_worker EXCEPT TABLE tenant_3.citus_local_3)
    );
ROLLBACK;

ALTER TABLE regular_schema.citus_local_3 SET SCHEMA tenant_3;
SELECT COUNT(*) = 0 FROM (
    (TABLE tenant_3.citus_local_3) EXCEPT (TABLE regular_schema.old_data_worker)
    UNION
    (TABLE regular_schema.old_data_worker EXCEPT TABLE tenant_3.citus_local_3)
);

CREATE TABLE regular_schema.local_table_1 (
    col_1 int,
    col_2 text,
    col_3 text GENERATED ALWAYS AS (col_1::text || '_gen') stored,
    col_4 bigint DEFAULT 42,
    col_5 bigint GENERATED BY DEFAULT AS IDENTITY (START WITH 1 INCREMENT BY 1),
    col_6 int GENERATED ALWAYS as (col_1 * 2) stored
);

INSERT INTO regular_schema.local_table_1 (col_1, col_2, col_4, col_5)
OVERRIDING SYSTEM VALUE
SELECT
    i, -- col_1
    'text_' || i, -- col_2
    i * 10, -- col_4
    100 + i -- col_5
FROM generate_series(1, 1000) AS i;

ALTER TABLE regular_schema.local_table_1 DROP COLUMN col_2;
ALTER TABLE regular_schema.local_table_1 DROP COLUMN col_5;

SELECT * INTO regular_schema.old_local_table_1 FROM regular_schema.local_table_1;

CREATE SCHEMA tenant_7;

-- test the same using a local table on this worker node
BEGIN;
    ALTER TABLE regular_schema.local_table_1 SET SCHEMA tenant_7;

    SELECT COUNT(*) = 0 FROM (
        (TABLE tenant_7.local_table_1) EXCEPT (TABLE regular_schema.old_local_table_1)
        UNION
        (TABLE regular_schema.old_local_table_1 EXCEPT TABLE tenant_7.local_table_1)
    );
ROLLBACK;

ALTER TABLE regular_schema.local_table_1 SET SCHEMA tenant_7;

SELECT COUNT(*) = 0 FROM (
    (TABLE tenant_7.local_table_1) EXCEPT (TABLE regular_schema.old_local_table_1)
    UNION
    (TABLE regular_schema.old_local_table_1 EXCEPT TABLE tenant_7.local_table_1)
);

SELECT pg_catalog.pg_table_size('tenant_7.local_table_1'::regclass) > 8192 as shell_table_has_data;
SELECT COUNT(*)=1000 FROM tenant_7.local_table_1;

SELECT truncate_local_data_after_distributing_table('tenant_7.local_table_1');

SELECT pg_catalog.pg_table_size('tenant_7.local_table_1'::regclass) = 8192 as shell_table_doesnt_have_data;
SELECT COUNT(*)=1000 FROM tenant_7.local_table_1;

CREATE SCHEMA tenant_8;

CREATE SEQUENCE dist_seq;
CREATE TABLE tenant_8.table_1(a bigint DEFAULT nextval('dist_seq') UNIQUE, "b" text, c bigint GENERATED BY DEFAULT AS IDENTITY);
INSERT INTO tenant_8.table_1("b") VALUES ('test');

BEGIN;
    -- add column
    ALTER TABLE tenant_8.table_1 ADD COLUMN d bigint DEFAULT 2;
    SELECT * FROM tenant_8.table_1 ORDER BY c;

    -- alter default, set to 3
    ALTER TABLE tenant_8.table_1 ALTER COLUMN d SET DEFAULT 3;
    INSERT INTO tenant_8.table_1("b") VALUES ('test');
    SELECT * FROM tenant_8.table_1 ORDER BY c;

    -- drop default, see null
    ALTER TABLE tenant_8.table_1 ALTER COLUMN d DROP DEFAULT;
    INSERT INTO tenant_8.table_1("b") VALUES ('test');
    SELECT * FROM tenant_8.table_1 ORDER BY c;

    -- cleanup the rows that were added to test the default behavior
    DELETE FROM tenant_8.table_1 WHERE "b" = 'test' AND a > 1;
COMMIT;

-- alter column type
ALTER TABLE tenant_8.table_1 ALTER COLUMN d TYPE text;
UPDATE tenant_8.table_1 SET d = 'this is a text' WHERE d = '2';
SELECT * FROM tenant_8.table_1 ORDER BY c;

-- drop seq column
ALTER TABLE tenant_8.table_1 DROP COLUMN a;
SELECT * FROM tenant_8.table_1 ORDER BY c;

-- add not null constraint
ALTER TABLE tenant_8.table_1 ALTER COLUMN b SET NOT NULL;

-- we want to hide the error message context because the node reporting the foreign key
-- violation might change from one run to another.
\set VERBOSITY terse

-- not null constraint violation, error out
INSERT INTO tenant_8.table_1 VALUES (NULL, 2, 'test');

\set VERBOSITY default

-- drop not null constraint and try again
ALTER TABLE tenant_8.table_1 ALTER COLUMN b DROP NOT NULL;
INSERT INTO tenant_8.table_1 VALUES (NULL, 3, 'test');
SELECT * FROM tenant_8.table_1 ORDER BY c;

-- add exclusion constraint
ALTER TABLE tenant_8.table_1 ADD CONSTRAINT exc_b EXCLUDE USING btree (b with =);

-- rename the exclusion constraint, errors out
ALTER TABLE tenant_8.table_1 RENAME CONSTRAINT exc_b TO exc_b_1;

-- create exclusion constraint without a name
ALTER TABLE tenant_8.table_1 ADD EXCLUDE USING btree (b with =);

INSERT INTO tenant_8.table_1 VALUES (100, 150, 'test150');

-- similarly, we want to hide the error message context here as well
\set VERBOSITY terse

-- should error out due to exclusion constraint violation
INSERT INTO tenant_8.table_1 VALUES (100, 151, 'test151');

\set VERBOSITY default

-- test setting autovacuum option
ALTER TABLE tenant_8.table_1 SET (autovacuum_enabled = false);

BEGIN;
    -- test multiple subcommands
    ALTER TABLE tenant_8.table_1 ADD COLUMN int_column1 INTEGER, DROP COLUMN d, ADD COLUMN e int;

    UPDATE tenant_8.table_1 SET e = c * 10;

    -- test unique constraint without a name
    ALTER TABLE tenant_8.table_1 ADD UNIQUE ("b");

    -- test add / drop primary key
    ALTER TABLE tenant_8.table_1 ADD PRIMARY KEY (c);
    ALTER TABLE tenant_8.table_1 DROP CONSTRAINT table_1_pkey;
    ALTER TABLE tenant_8.table_1 ADD PRIMARY KEY (e);

    SELECT * FROM tenant_8.table_1 ORDER BY c;

    -- test renaming table
    ALTER TABLE tenant_8.table_1 RENAME TO table_2;

    -- test renaming column
    ALTER TABLE tenant_8.table_2 RENAME COLUMN e TO f;

    -- test renaming an index
    ALTER INDEX tenant_8.table_1_pkey RENAME TO table_1_pkey_renamed;
COMMIT;

-- make sure that the shell table definition is same on all nodes
SELECT result FROM run_command_on_all_nodes(
$$
SELECT regexp_replace(
    string_agg(ddl_events, '; '),
    -- TODOTASK: suppress sequence ranges for now, until we fix the code to properly assign them on all nodes when creating a distributed-schema table from a worker
    'INCREMENT BY (\d+) MINVALUE (\d+) MAXVALUE (\d+) START WITH (\d+) CACHE (\d+) ',
    'INCREMENT BY XXX MINVALUE YYY MAXVALUE ZZZ START WITH AAA CACHE BBB '
) FROM master_get_table_ddl_events('tenant_8.table_2') AS ddl_events;
$$
) JOIN pg_dist_node USING (nodeid) ORDER BY nodeport;

CREATE SCHEMA alter_table_add_column;

\c - - - :master_port

CREATE SCHEMA alter_table_add_column_other_schema;

CREATE OR REPLACE FUNCTION alter_table_add_column_other_schema.my_random(numeric)
  RETURNS numeric AS
$$
BEGIN
  RETURN 7 * $1;
END;
$$
LANGUAGE plpgsql IMMUTABLE;

SET search_path TO alter_table_add_column;

CREATE COLLATION caseinsensitive (
	provider = icu,
	locale = 'und-u-ks-level2'
);

CREATE TYPE "simple_!\'custom_type" AS (a integer, b integer);

\c - - - :worker_1_port

SELECT 1 FROM run_command_on_coordinator($$ALTER SYSTEM SET citus.next_shard_id TO 2092000;$$);
SELECT 1 FROM run_command_on_coordinator($$SELECT pg_reload_conf();$$);
SELECT pg_sleep(0.1);

SET citus.shard_replication_factor TO 1;
SET search_path TO alter_table_add_column;
SET citus.enable_schema_based_sharding TO ON;
SET client_min_messages TO NOTICE;

CREATE TABLE referenced (int_col integer PRIMARY KEY);
CREATE TABLE referencing (text_col text);

-- test alter table add column with various subcommands and options
ALTER TABLE referencing ADD COLUMN test_1 integer DEFAULT (alter_table_add_column_other_schema.my_random(7) + random() + 5) NOT NULL CONSTRAINT fkey REFERENCES referenced(int_col) ON UPDATE SET DEFAULT ON DELETE CASCADE DEFERRABLE INITIALLY DEFERRED;
ALTER TABLE referencing ADD COLUMN test_2 integer UNIQUE REFERENCES referenced(int_col) ON UPDATE CASCADE ON DELETE SET DEFAULT NOT DEFERRABLE INITIALLY IMMEDIATE;

BEGIN;
    ALTER TABLE referencing ADD COLUMN test_3 integer GENERATED ALWAYS AS (test_1 * alter_table_add_column_other_schema.my_random(1)) STORED UNIQUE REFERENCES referenced(int_col) MATCH FULL;
    ALTER TABLE referencing ADD COLUMN test_4 integer PRIMARY KEY WITH (fillfactor=70) NOT NULL REFERENCES referenced(int_col) MATCH SIMPLE ON UPDATE CASCADE ON DELETE SET DEFAULT;
    ALTER TABLE referencing ADD COLUMN test_5 integer CONSTRAINT unique_c UNIQUE WITH (fillfactor=50) NULL;
COMMIT;

ALTER TABLE referencing ADD COLUMN test_6 text COMPRESSION pglz COLLATE caseinsensitive NOT NULL;
ALTER TABLE referencing ADD COLUMN "test_\'!7" "simple_!\'custom_type";

-- we give up deparsing ALTER TABLE command if it needs to create a check constraint, and we fallback to legacy behavior
ALTER TABLE referencing ADD COLUMN test_8 integer CHECK (test_8 > 0);
ALTER TABLE referencing ADD COLUMN test_8 integer CONSTRAINT check_test_8 CHECK (test_8 > 0);

-- error out properly even if the REFERENCES does not include the column list of the referenced table
ALTER TABLE referencing ADD COLUMN test_9 bool, ADD COLUMN test_10 int REFERENCES referenced;
ALTER TABLE referencing ADD COLUMN test_9 bool, ADD COLUMN test_10 int REFERENCES referenced(int_col);

-- supress notice messages because we want to ignore the notice about skipping adding test_6
-- on the shard, if the shard is local
SET client_min_messages TO WARNING;

-- try to add test_6 again, but with IF NOT EXISTS
ALTER TABLE referencing ADD COLUMN IF NOT EXISTS test_6 text;
ALTER TABLE referencing ADD COLUMN IF NOT EXISTS test_6 integer;

SET client_min_messages TO NOTICE;

SELECT result FROM run_command_on_all_nodes(
  $$SELECT get_grouped_fkey_constraints FROM get_grouped_fkey_constraints('alter_table_add_column.referencing')$$
)
JOIN pg_dist_node USING (nodeid)
ORDER BY result;

SELECT result FROM run_command_on_all_nodes(
  $$SELECT get_index_defs FROM get_index_defs('alter_table_add_column', 'referencing')$$
)
JOIN pg_dist_node USING (nodeid)
ORDER BY result;

SELECT result FROM run_command_on_all_nodes(
  $$SELECT get_column_defaults FROM get_column_defaults('alter_table_add_column', 'referencing')$$
)
JOIN pg_dist_node USING (nodeid)
ORDER BY result;

SELECT result FROM run_command_on_all_nodes(
  $$SELECT get_column_attrs FROM get_column_attrs('alter_table_add_column.referencing')$$
)
JOIN pg_dist_node USING (nodeid)
ORDER BY result;

CREATE TABLE tenant_8.table_3 (a int, b text);
INSERT INTO tenant_8.table_3 SELECT i, 'text_' || i FROM generate_series(1, 100) AS i;

-- test truncate
TRUNCATE tenant_8.table_3;
SELECT result FROM run_command_on_all_nodes($$
    SELECT COUNT(*)=0 FROM tenant_8.table_3
$$);

BEGIN;

    CREATE SCHEMA tenant_9;

    CREATE SEQUENCE tenant_9.seq_1 START 5000 INCREMENT 5;

    CREATE USER tenant_9_owner;
    CREATE TABLE tenant_9.table_1 (
        a bigint NULL DEFAULT 100,
        b text COLLATE "C" DEFAULT now()::text,
        c int DEFAULT nextval('tenant_9.seq_1'::regclass),
        d bigint GENERATED BY DEFAULT AS IDENTITY
        (
            MINVALUE 5
            MAXVALUE 100
            START WITH 10
        ),
        e int NOT NULL REFERENCES regular_schema.reference_table(id) MATCH FULL ON UPDATE RESTRICT ON DELETE CASCADE DEFERRABLE INITIALLY DEFERRED,
        f int GENERATED ALWAYS AS (c * 2) STORED,
        CONSTRAINT table_1_pkey PRIMARY KEY (a, b),
        CONSTRAINT table_1_unique_b UNIQUE NULLS DISTINCT (b, a),
        CONSTRAINT table_1_check_a_positive CHECK (a > 0)
    )
    PARTITION BY RANGE (a);
COMMIT;

SELECT result FROM run_command_on_all_nodes(
$$
SELECT regexp_replace(
    string_agg(ddl_events, '; '),
    -- TODOTASK: suppress sequence ranges for now, until we fix the code to properly assign them on all nodes when creating a distributed-schema table from a worker
    'INCREMENT BY (\d+) MINVALUE (\d+) MAXVALUE (\d+) START WITH (\d+) CACHE (\d+) ',
    'INCREMENT BY XXX MINVALUE YYY MAXVALUE ZZZ START WITH AAA CACHE BBB '
) FROM master_get_table_ddl_events('tenant_9.table_1') AS ddl_events;
$$
) JOIN pg_dist_node USING (nodeid) ORDER BY nodeport;

CREATE TABLE tenant_9.table_2 (
    a serial,
    b bigserial
)
WITH (autovacuum_enabled = false, fillfactor = 20);

SELECT result FROM run_command_on_all_nodes(
$$
SELECT string_agg(ddl_events, '; ') FROM master_get_table_ddl_events('tenant_9.table_2') AS ddl_events;
$$
) JOIN pg_dist_node USING (nodeid) ORDER BY nodeport;

CREATE UNLOGGED TABLE tenant_9.table_3 (
    a int,
    b text STORAGE EXTERNAL COMPRESSION pglz,
    c int generated always as (a * 2) stored,
    d int generated always as (a * 3) stored,
    e text CONSTRAINT table_3_e_check CHECK (length(e) < 25)
);

\c - - - :master_port

CREATE UNIQUE INDEX new_index ON tenant_9.table_3 USING btree (a);

SELECT result FROM run_command_on_all_nodes($Q$
	SET citus.enable_ddl_propagation TO off;
	CREATE FUNCTION fake_am_handler(internal)
	RETURNS table_am_handler
	AS 'citus'
	LANGUAGE C;
	CREATE ACCESS METHOD fake_am TYPE TABLE HANDLER fake_am_handler;
    SET citus.enable_ddl_propagation TO on;
$Q$);

-- Since Citus assumes access methods are part of the extension, make fake_am
-- owned manually to be able to pass checks on Citus while distributing tables.
SET client_min_messages TO WARNING;
ALTER EXTENSION citus ADD ACCESS METHOD fake_am;
SET client_min_messages TO NOTICE;

CREATE ROLE test_non_super_user;
ALTER ROLE test_non_super_user NOSUPERUSER;

CREATE ROLE rls_test_user_1 WITH LOGIN;
ALTER ROLE rls_test_user_1 NOSUPERUSER;

CREATE ROLE rls_test_user_2 WITH LOGIN;
ALTER ROLE rls_test_user_2 NOSUPERUSER;

CREATE TEXT SEARCH CONFIGURATION regular_schema.text_search_cfg (parser = default);

GRANT USAGE ON SCHEMA tenant_9 TO rls_test_user_1, rls_test_user_2;

\c - - - :worker_1_port

SELECT 1 FROM run_command_on_coordinator($$ALTER SYSTEM SET citus.next_shard_id TO 2093000;$$);
SELECT 1 FROM run_command_on_coordinator($$SELECT pg_reload_conf();$$);
SELECT pg_sleep(0.1);

SET citus.shard_replication_factor TO 1;
SET search_path TO alter_table_add_column;
SET citus.enable_schema_based_sharding TO ON;
SET client_min_messages TO NOTICE;

ALTER TABLE tenant_9.table_3 SET LOGGED;
ALTER TABLE tenant_9.table_3 ALTER COLUMN b SET DATA TYPE varchar(100) USING b::varchar(100);
ALTER TABLE tenant_9.table_3 ALTER COLUMN e SET COMPRESSION pglz;
ALTER TABLE tenant_9.table_3 ADD UNIQUE USING INDEX new_index;
ALTER TABLE tenant_9.table_3 VALIDATE CONSTRAINT table_3_e_check;
ALTER TABLE tenant_9.table_3 ALTER COLUMN a SET NOT NULL;
ALTER TABLE tenant_9.table_3 REPLICA IDENTITY USING INDEX new_index;
CLUSTER tenant_9.table_3 USING new_index;

-- not supported but let's keep as negative tests for future coverage
ALTER TABLE tenant_9.table_3 ALTER COLUMN d DROP EXPRESSION;
ALTER TABLE tenant_9.table_3 ALTER COLUMN c SET GENERATED BY DEFAULT RESTART WITH 500;
ALTER TABLE tenant_9.table_3 ALTER COLUMN c DROP IDENTITY IF EXISTS;
ALTER TABLE tenant_9.table_3 ALTER COLUMN a SET STATISTICS 50;
ALTER TABLE tenant_9.table_3 ALTER COLUMN b SET STORAGE RESET;
ALTER TABLE tenant_9.table_3 ALTER COLUMN b SET STORAGE MAIN;
ALTER TABLE tenant_9.table_3 CLUSTER ON new_index;

CREATE TABLE tenant_9.table_4 (a int, b text);

ALTER TABLE tenant_9.table_4 SET UNLOGGED;
ALTER TABLE tenant_9.table_4 SET ACCESS METHOD fake_am;
ALTER TABLE tenant_9.table_4 OWNER TO test_non_super_user;

SET client_min_messages TO ERROR;
CREATE TABLE tenant_9.table_5 (a int, b text) USING fake_am;
SET client_min_messages TO NOTICE;

SET citus.enable_schema_based_sharding TO OFF;
CREATE SCHEMA regular_schema_worker_1;
SET citus.enable_schema_based_sharding TO ON;

CREATE TABLE regular_schema_worker_1.local_table_1 (
    a int,
    b text
);

CREATE STATISTICS ON a, b FROM regular_schema_worker_1.local_table_1;

CREATE INDEX text_search_idx ON regular_schema_worker_1.local_table_1
USING gin (to_tsvector('regular_schema.text_search_cfg'::regconfig, (COALESCE(b, ''::character varying))::text));

ALTER TABLE regular_schema_worker_1.local_table_1 SET SCHEMA tenant_9;
ALTER TABLE tenant_9.local_table_1 RENAME TO table_6;

-- we don't support yet but let's still keep it
ALTER TABLE tenant_9.table_6 ALTER COLUMN 2 SET STATISTICS 101;

SET citus.enable_schema_based_sharding TO OFF;
CREATE SCHEMA regular_schema_worker_2;
SET citus.enable_schema_based_sharding TO ON;

CREATE TABLE regular_schema_worker_2.local_table_2 (a int, tenant_id int);
INSERT INTO regular_schema_worker_2.local_table_2 SELECT i, 1 FROM generate_series(1, 5) AS i;
INSERT INTO regular_schema_worker_2.local_table_2 SELECT i, 2 FROM generate_series(6, 10) AS i;
CREATE POLICY local_table_2_select_policy ON regular_schema_worker_2.local_table_2 FOR SELECT TO rls_test_user_1, rls_test_user_2 USING (current_user = 'rls_test_user_' || tenant_id::text);
GRANT SELECT ON TABLE regular_schema_worker_2.local_table_2 TO rls_test_user_1, rls_test_user_2;

ALTER TABLE regular_schema_worker_2.local_table_2 SET SCHEMA tenant_9;
ALTER TABLE tenant_9.local_table_2 RENAME TO table_7;

SET ROLE rls_test_user_1;
SELECT COUNT(*)=10 FROM tenant_9.table_7;

SET ROLE rls_test_user_2;
SELECT COUNT(*)=10 FROM tenant_9.table_7;

SET ROLE postgres;

ALTER TABLE tenant_9.table_7 ENABLE ROW LEVEL SECURITY;

SET ROLE rls_test_user_1;
SELECT COUNT(*)=5 FROM tenant_9.table_7;

SET ROLE rls_test_user_2;
SELECT COUNT(*)=5 FROM tenant_9.table_7;

SET ROLE postgres;

SET citus.enable_schema_based_sharding TO OFF;
CREATE SCHEMA regular_schema_worker_3;
SET citus.enable_schema_based_sharding TO ON;

CREATE TABLE regular_schema_worker_3.local_table_3 (value int, tenant_id int);

\c - - - :master_port

CREATE FUNCTION regular_schema.local_table_3_increment_value_tf() RETURNS trigger AS $local_table_3_increment_value_tf$
BEGIN
    UPDATE tenant_9.table_8 SET value=value+1;
    RETURN NEW;
END;
$local_table_3_increment_value_tf$ LANGUAGE plpgsql;

CREATE FUNCTION regular_schema.local_table_3_notice_value_tf() RETURNS trigger AS $local_table_3_notice_value_tf$
BEGIN
    RAISE NOTICE 'New value is %', NEW.value;
    RETURN NEW;
END;
$local_table_3_notice_value_tf$ LANGUAGE plpgsql;

\c - - - :worker_1_port

SELECT 1 FROM run_command_on_coordinator($$ALTER SYSTEM SET citus.next_shard_id TO 2093500;$$);
SELECT 1 FROM run_command_on_coordinator($$SELECT pg_reload_conf();$$);
SELECT pg_sleep(0.1);

SET citus.shard_replication_factor TO 1;
SET search_path TO alter_table_add_column;
SET citus.enable_schema_based_sharding TO ON;
SET client_min_messages TO NOTICE;

CREATE TRIGGER local_table_3_insert_statement_trigger
AFTER INSERT ON regular_schema_worker_3.local_table_3
FOR EACH STATEMENT EXECUTE FUNCTION regular_schema.local_table_3_increment_value_tf();

-- Disable this to make sure that we allow triggers on distributed-schema tables
-- regardless of this setting as we don't think that triggers are unsafe on such
-- tables.
SET citus.enable_unsafe_triggers TO OFF;

ALTER TABLE regular_schema_worker_3.local_table_3 SET SCHEMA tenant_9;
ALTER TABLE tenant_9.local_table_3 RENAME TO table_8;

INSERT INTO tenant_9.table_8 VALUES (1), (1);

-- Show that trigger is executed only once, we should see two "2"s, not "1",
-- i.e., the trigger didn't fire, and not "3", i.e., the trigger fired more
-- than once.
SELECT * FROM tenant_9.table_8;

CREATE TRIGGER local_table_3_update_row_trigger
AFTER UPDATE ON tenant_9.table_8
FOR EACH ROW EXECUTE FUNCTION regular_schema.local_table_3_notice_value_tf();

-- we want to hide the error message context because the node sending
-- the notice might change from one run to another.
\set VERBOSITY terse
UPDATE tenant_9.table_8 SET value=0;
\set VERBOSITY default

ALTER TABLE tenant_9.table_8 DISABLE TRIGGER local_table_3_update_row_trigger;

-- no notice should be raised
UPDATE tenant_9.table_8 SET value=0;

ALTER TABLE tenant_9.table_8 DISABLE TRIGGER ALL;

INSERT INTO tenant_9.table_8 VALUES (1), (1);

SELECT * FROM tenant_9.table_8 ORDER BY value;

ALTER TABLE tenant_9.table_8 ENABLE TRIGGER ALL;
ALTER TABLE tenant_9.table_8 DISABLE TRIGGER local_table_3_insert_statement_trigger;

TRUNCATE tenant_9.table_8;

INSERT INTO tenant_9.table_8 VALUES (2), (2);

-- we want to hide the error message context because the node sending
-- the notice might change from one run to another.
\set VERBOSITY terse
UPDATE tenant_9.table_8 SET value=5;
\set VERBOSITY default

SELECT * FROM tenant_9.table_8 ORDER BY value;

ALTER TRIGGER local_table_3_insert_statement_trigger ON tenant_9.table_8 RENAME TO local_table_3_insert_statement_trigger_renamed;

CREATE TRIGGER trigger_to_drop
AFTER UPDATE ON tenant_9.table_8
FOR EACH ROW EXECUTE FUNCTION regular_schema.local_table_3_notice_value_tf();

DROP TRIGGER trigger_to_drop ON tenant_9.table_8;

-- not supported at all
ALTER TRIGGER local_table_3_insert_statement_trigger_renamed ON tenant_9.table_8 DEPENDS ON EXTENSION citus;

-- make sure that the shell table definition is same on all nodes
SELECT result FROM run_command_on_all_nodes(
$$
SELECT string_agg(ddl_events, '; ') FROM master_get_table_ddl_events('tenant_9.table_3') AS ddl_events;
$$
) JOIN pg_dist_node USING (nodeid) ORDER BY nodeport;

SELECT result FROM run_command_on_all_nodes(
$$
SELECT string_agg(ddl_events, '; ') FROM master_get_table_ddl_events('tenant_9.table_4') AS ddl_events;
$$
) JOIN pg_dist_node USING (nodeid) ORDER BY nodeport;

SELECT result FROM run_command_on_all_nodes(
$$
SELECT string_agg(ddl_events, '; ') FROM master_get_table_ddl_events('tenant_9.table_5') AS ddl_events;
$$
) JOIN pg_dist_node USING (nodeid) ORDER BY nodeport;

SELECT result FROM run_command_on_all_nodes(
$$
SELECT string_agg(ddl_events, '; ') FROM master_get_table_ddl_events('tenant_9.table_6') AS ddl_events;
$$
) JOIN pg_dist_node USING (nodeid) ORDER BY nodeport;

SELECT result FROM run_command_on_all_nodes(
$$
SELECT replace(
    string_agg(ddl_events, '; '),
    -- to avoid adding another test ouput for PG < 17, replace this with an empty string
    ' GRANT MAINTAIN ON tenant_9.table_7 TO postgres;',
    ''
) FROM master_get_table_ddl_events('tenant_9.table_7') AS ddl_events;
$$
) JOIN pg_dist_node USING (nodeid) ORDER BY nodeport;

SELECT result FROM run_command_on_all_nodes(
$$
SELECT string_agg(ddl_events, '; ') FROM master_get_table_ddl_events('tenant_9.table_8') AS ddl_events;
$$
) JOIN pg_dist_node USING (nodeid) ORDER BY nodeport;

-- cleanup
\c - - - :master_port

SET client_min_messages TO WARNING;
DROP SCHEMA tenant_1, tenant_2, tenant_3, tenant_4, tenant_5, tenant_6, tenant_7, tenant_8, tenant_9, alter_table_add_column CASCADE;
DROP SCHEMA regular_schema, alter_table_add_column_other_schema, regular_schema_worker_1, regular_schema_worker_2, regular_schema_worker_3 CASCADE;
DROP FUNCTION create_citus_local_with_data(text);
DROP SEQUENCE dist_seq;
DROP ROLE tenant_9_owner;
ALTER EXTENSION citus DROP ACCESS METHOD fake_am;

SELECT result FROM run_command_on_all_nodes($Q$
	DROP FUNCTION fake_am_handler(internal) CASCADE;
$Q$);

DROP ROLE test_non_super_user, rls_test_user_1, rls_test_user_2;

-- reset it fwiw
ALTER SYSTEM RESET citus.next_shard_id;
SELECT pg_reload_conf();
SELECT pg_sleep(0.1);
