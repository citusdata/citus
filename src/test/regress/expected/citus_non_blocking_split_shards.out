/*
Citus Shard Split Test.The test is model similar to 'shard_move_constraints'.
Here is a high level overview of test plan:
 1. Create a table 'sensors' (ShardCount = 2) to be split. Add indexes and statistics on this table.
 2. Create two other tables: 'reference_table' and 'colocated_dist_table', co-located with sensors.
 3. Create Foreign key constraints between the two co-located distributed tables.
 4. Load data into the three tables.
 5. Move one of the shards for 'sensors' to test ShardMove -> Split.
 6. Trigger Split on both shards of 'sensors'. This will also split co-located tables.
 7. Move one of the split shard to test Split -> ShardMove.
 8. Split an already split shard second time on a different schema.
 9. Create a colocated table with no replica identity.
 10. Show we do not allow Split with the shard transfer mode 'auto' if any colocated table has no replica identity.
 11. Drop the colocated table with no replica identity.
 12. Show we allow Split with the shard transfer mode 'auto' if all colocated tables has replica identity.
*/
CREATE SCHEMA "citus_split_test_schema";
-- Disable Deferred drop auto cleanup to avoid flaky tests.
ALTER SYSTEM SET citus.defer_shard_delete_interval TO -1;
SELECT pg_reload_conf();
 pg_reload_conf
---------------------------------------------------------------------
 t
(1 row)

CREATE ROLE test_shard_split_role WITH LOGIN;
GRANT USAGE, CREATE ON SCHEMA "citus_split_test_schema" TO test_shard_split_role;
SET ROLE test_shard_split_role;
SET search_path TO "citus_split_test_schema";
SET citus.next_shard_id TO 8981000;
SET citus.next_placement_id TO 8610000;
SET citus.shard_count TO 2;
SET citus.shard_replication_factor TO 1;
-- BEGIN: Create table to split, along with other co-located tables. Add indexes, statistics etc.
CREATE TABLE sensors(
    measureid               integer,
    eventdatetime           date,
    measure_data            jsonb,
	meaure_quantity         decimal(15, 2),
    measure_status          char(1),
	measure_comment         varchar(44),
    PRIMARY KEY (measureid, eventdatetime, measure_data));
CREATE INDEX index_on_sensors ON sensors(lower(measureid::text));
ALTER INDEX index_on_sensors ALTER COLUMN 1 SET STATISTICS 1000;
CREATE INDEX hash_index_on_sensors ON sensors USING HASH((measure_data->'IsFailed'));
CREATE INDEX index_with_include_on_sensors ON sensors ((measure_data->'IsFailed')) INCLUDE (measure_data, eventdatetime, measure_status);
CREATE STATISTICS stats_on_sensors (dependencies) ON measureid, eventdatetime FROM sensors;
SELECT create_distributed_table('sensors', 'measureid', colocate_with:='none');
 create_distributed_table
---------------------------------------------------------------------

(1 row)

-- END: Create table to split, along with other co-located tables. Add indexes, statistics etc.
-- BEGIN: Create co-located distributed and reference tables.
CREATE TABLE reference_table (measureid integer PRIMARY KEY);
SELECT create_reference_table('reference_table');
 create_reference_table
---------------------------------------------------------------------

(1 row)

CREATE TABLE colocated_dist_table (measureid integer PRIMARY KEY);
CLUSTER colocated_dist_table USING colocated_dist_table_pkey;
SELECT create_distributed_table('colocated_dist_table', 'measureid', colocate_with:='sensors');
 create_distributed_table
---------------------------------------------------------------------

(1 row)

CREATE TABLE table_with_index_rep_identity(key int NOT NULL);
CREATE UNIQUE INDEX uqx ON table_with_index_rep_identity(key);
ALTER TABLE table_with_index_rep_identity REPLICA IDENTITY USING INDEX uqx;
CLUSTER table_with_index_rep_identity USING uqx;
SELECT create_distributed_table('table_with_index_rep_identity', 'key', colocate_with:='sensors');
 create_distributed_table
---------------------------------------------------------------------

(1 row)

-- END: Create co-located distributed and reference tables.
-- BEGIN : Create Foreign key constraints.
ALTER TABLE sensors ADD CONSTRAINT fkey_table_to_dist FOREIGN KEY (measureid) REFERENCES colocated_dist_table(measureid);
-- END : Create Foreign key constraints.
-- BEGIN : Load data into tables.
INSERT INTO reference_table SELECT i FROM generate_series(0,1000)i;
INSERT INTO colocated_dist_table SELECT i FROM generate_series(0,1000)i;
INSERT INTO sensors SELECT i, '2020-01-05', '{}', 11011.10, 'A', 'I <3 Citus' FROM generate_series(0,1000)i;
SELECT COUNT(*) FROM sensors;
 count
---------------------------------------------------------------------
  1001
(1 row)

SELECT COUNT(*) FROM reference_table;
 count
---------------------------------------------------------------------
  1001
(1 row)

SELECT COUNT(*) FROM colocated_dist_table;
 count
---------------------------------------------------------------------
  1001
(1 row)

-- END: Load data into tables.
-- BEGIN : Display current state.
SELECT shard.shardid, logicalrelid, shardminvalue, shardmaxvalue, nodename, nodeport
  FROM pg_dist_shard AS shard
  INNER JOIN pg_dist_placement placement ON shard.shardid = placement.shardid
  INNER JOIN pg_dist_node       node     ON placement.groupid = node.groupid
  INNER JOIN pg_catalog.pg_class cls     ON shard.logicalrelid = cls.oid
  WHERE node.noderole = 'primary' AND (logicalrelid = 'sensors'::regclass OR logicalrelid = 'colocated_dist_table'::regclass OR logicalrelid = 'table_with_index_rep_identity'::regclass)
  ORDER BY logicalrelid, shardminvalue::BIGINT;
 shardid |         logicalrelid          | shardminvalue | shardmaxvalue | nodename  | nodeport
---------------------------------------------------------------------
 8981000 | sensors                       | -2147483648   | -1            | localhost |    57637
 8981001 | sensors                       | 0             | 2147483647    | localhost |    57638
 8981003 | colocated_dist_table          | -2147483648   | -1            | localhost |    57637
 8981004 | colocated_dist_table          | 0             | 2147483647    | localhost |    57638
 8981005 | table_with_index_rep_identity | -2147483648   | -1            | localhost |    57637
 8981006 | table_with_index_rep_identity | 0             | 2147483647    | localhost |    57638
(6 rows)

\c - - - :worker_1_port
    SET search_path TO "citus_split_test_schema", public, pg_catalog;
    SET citus.show_shards_for_app_name_prefixes = '*';
    SELECT tbl.relname, fk."Constraint", fk."Definition"
            FROM pg_catalog.pg_class tbl
            JOIN public.table_fkeys fk on tbl.oid = fk.relid
            WHERE tbl.relname like 'sensors_%'
            ORDER BY 1, 2;
     relname     |         Constraint         |                                 Definition
---------------------------------------------------------------------
 sensors_8981000 | fkey_table_to_dist_8981000 | FOREIGN KEY (measureid) REFERENCES colocated_dist_table_8981003(measureid)
(1 row)

    SELECT tablename, indexdef FROM pg_indexes WHERE tablename like 'sensors_%' ORDER BY 1,2;
    tablename    |                                                                                                indexdef
---------------------------------------------------------------------
 sensors_8981000 | CREATE INDEX hash_index_on_sensors_8981000 ON citus_split_test_schema.sensors_8981000 USING hash (((measure_data -> 'IsFailed'::text)))
 sensors_8981000 | CREATE INDEX index_on_sensors_8981000 ON citus_split_test_schema.sensors_8981000 USING btree (lower((measureid)::text))
 sensors_8981000 | CREATE INDEX index_with_include_on_sensors_8981000 ON citus_split_test_schema.sensors_8981000 USING btree (((measure_data -> 'IsFailed'::text))) INCLUDE (measure_data, eventdatetime, measure_status)
 sensors_8981000 | CREATE UNIQUE INDEX sensors_pkey_8981000 ON citus_split_test_schema.sensors_8981000 USING btree (measureid, eventdatetime, measure_data)
(4 rows)

    SELECT tablename, indexdef FROM pg_indexes WHERE tablename like 'table_with_index_rep_identity_%' ORDER BY 1,2;
               tablename               |                                                      indexdef
---------------------------------------------------------------------
 table_with_index_rep_identity_8981005 | CREATE UNIQUE INDEX uqx_8981005 ON citus_split_test_schema.table_with_index_rep_identity_8981005 USING btree (key)
(1 row)

    SELECT stxname FROM pg_statistic_ext
    WHERE stxnamespace IN (
        SELECT oid
        FROM pg_namespace
        WHERE nspname IN ('citus_split_test_schema')
    )
    ORDER BY stxname ASC;
         stxname
---------------------------------------------------------------------
 stats_on_sensors
 stats_on_sensors_8981000
(2 rows)

\c - - - :worker_2_port
    SET search_path TO "citus_split_test_schema", public, pg_catalog;
    SET citus.show_shards_for_app_name_prefixes = '*';
    SELECT tbl.relname, fk."Constraint", fk."Definition"
            FROM pg_catalog.pg_class tbl
            JOIN public.table_fkeys fk on tbl.oid = fk.relid
            WHERE tbl.relname like 'sensors_%'
            ORDER BY 1, 2;
     relname     |         Constraint         |                                 Definition
---------------------------------------------------------------------
 sensors_8981001 | fkey_table_to_dist_8981001 | FOREIGN KEY (measureid) REFERENCES colocated_dist_table_8981004(measureid)
(1 row)

    SELECT tablename, indexdef FROM pg_indexes WHERE tablename like 'sensors_%' ORDER BY 1,2;
    tablename    |                                                                                                indexdef
---------------------------------------------------------------------
 sensors_8981001 | CREATE INDEX hash_index_on_sensors_8981001 ON citus_split_test_schema.sensors_8981001 USING hash (((measure_data -> 'IsFailed'::text)))
 sensors_8981001 | CREATE INDEX index_on_sensors_8981001 ON citus_split_test_schema.sensors_8981001 USING btree (lower((measureid)::text))
 sensors_8981001 | CREATE INDEX index_with_include_on_sensors_8981001 ON citus_split_test_schema.sensors_8981001 USING btree (((measure_data -> 'IsFailed'::text))) INCLUDE (measure_data, eventdatetime, measure_status)
 sensors_8981001 | CREATE UNIQUE INDEX sensors_pkey_8981001 ON citus_split_test_schema.sensors_8981001 USING btree (measureid, eventdatetime, measure_data)
(4 rows)

    SELECT tablename, indexdef FROM pg_indexes WHERE tablename like 'table_with_index_rep_identity_%' ORDER BY 1,2;
               tablename               |                                                      indexdef
---------------------------------------------------------------------
 table_with_index_rep_identity_8981006 | CREATE UNIQUE INDEX uqx_8981006 ON citus_split_test_schema.table_with_index_rep_identity_8981006 USING btree (key)
(1 row)

    SELECT stxname FROM pg_statistic_ext
    WHERE stxnamespace IN (
        SELECT oid
        FROM pg_namespace
        WHERE nspname IN ('citus_split_test_schema')
    )
    ORDER BY stxname ASC;
         stxname
---------------------------------------------------------------------
 stats_on_sensors
 stats_on_sensors_8981001
(2 rows)

-- END : Display current state
-- BEGIN : Move one shard before we split it.
\c - postgres - :master_port
SET ROLE test_shard_split_role;
SET search_path TO "citus_split_test_schema";
SET citus.next_shard_id TO 8981007;
SELECT citus_move_shard_placement(8981000, 'localhost', :worker_1_port, 'localhost', :worker_2_port, shard_transfer_mode:='force_logical');
 citus_move_shard_placement
---------------------------------------------------------------------

(1 row)

-- END : Move one shard before we split it.
CALL pg_catalog.citus_cleanup_orphaned_shards();
NOTICE:  cleaned up 3 orphaned shards
-- BEGIN : Set node id variables
SELECT nodeid AS worker_1_node FROM pg_dist_node WHERE nodeport=:worker_1_port \gset
SELECT nodeid AS worker_2_node FROM pg_dist_node WHERE nodeport=:worker_2_port \gset
-- END   : Set node id variables
-- BEGIN : Split two shards : One with move and One without move.
-- Perform 2 way split
SELECT pg_catalog.citus_split_shard_by_split_points(
    8981000,
    ARRAY['-1073741824'],
    ARRAY[:worker_1_node, :worker_2_node],
    'force_logical');
 citus_split_shard_by_split_points
---------------------------------------------------------------------

(1 row)

-- BEGIN: Perform deferred cleanup.
SET client_min_messages TO WARNING;
CALL pg_catalog.citus_cleanup_orphaned_resources();
RESET client_min_messages;
-- END: Perform deferred cleanup.
-- Perform 3 way split
SELECT pg_catalog.citus_split_shard_by_split_points(
    8981001,
    ARRAY['536870911', '1610612735'],
    ARRAY[:worker_1_node, :worker_1_node, :worker_2_node],
    'force_logical');
 citus_split_shard_by_split_points
---------------------------------------------------------------------

(1 row)

-- END : Split two shards : One with move and One without move.
-- BEGIN: Perform deferred cleanup.
SET client_min_messages TO WARNING;
CALL pg_catalog.citus_cleanup_orphaned_resources();
RESET client_min_messages;
-- END: Perform deferred cleanup.
-- BEGIN : Move a shard post split.
SELECT citus_move_shard_placement(8981007, 'localhost', :worker_1_port, 'localhost', :worker_2_port, shard_transfer_mode:='block_writes');
 citus_move_shard_placement
---------------------------------------------------------------------

(1 row)

-- END : Move a shard post split.
CALL pg_catalog.citus_cleanup_orphaned_shards();
NOTICE:  cleaned up 3 orphaned shards
-- BEGIN : Display current state.
SELECT shard.shardid, logicalrelid, shardminvalue, shardmaxvalue, nodename, nodeport
  FROM pg_dist_shard AS shard
  INNER JOIN pg_dist_placement placement ON shard.shardid = placement.shardid
  INNER JOIN pg_dist_node       node     ON placement.groupid = node.groupid
  INNER JOIN pg_catalog.pg_class cls     ON shard.logicalrelid = cls.oid
  WHERE node.noderole = 'primary' AND (logicalrelid = 'sensors'::regclass OR logicalrelid = 'colocated_dist_table'::regclass OR logicalrelid = 'table_with_index_rep_identity'::regclass)
  ORDER BY logicalrelid, shardminvalue::BIGINT;
 shardid |         logicalrelid          | shardminvalue | shardmaxvalue | nodename  | nodeport
---------------------------------------------------------------------
 8981007 | sensors                       | -2147483648   | -1073741824   | localhost |    57638
 8981008 | sensors                       | -1073741823   | -1            | localhost |    57638
 8981013 | sensors                       | 0             | 536870911     | localhost |    57637
 8981014 | sensors                       | 536870912     | 1610612735    | localhost |    57637
 8981015 | sensors                       | 1610612736    | 2147483647    | localhost |    57638
 8981009 | colocated_dist_table          | -2147483648   | -1073741824   | localhost |    57638
 8981010 | colocated_dist_table          | -1073741823   | -1            | localhost |    57638
 8981016 | colocated_dist_table          | 0             | 536870911     | localhost |    57637
 8981017 | colocated_dist_table          | 536870912     | 1610612735    | localhost |    57637
 8981018 | colocated_dist_table          | 1610612736    | 2147483647    | localhost |    57638
 8981011 | table_with_index_rep_identity | -2147483648   | -1073741824   | localhost |    57638
 8981012 | table_with_index_rep_identity | -1073741823   | -1            | localhost |    57638
 8981019 | table_with_index_rep_identity | 0             | 536870911     | localhost |    57637
 8981020 | table_with_index_rep_identity | 536870912     | 1610612735    | localhost |    57637
 8981021 | table_with_index_rep_identity | 1610612736    | 2147483647    | localhost |    57638
(15 rows)

\c - - - :worker_1_port
    SET search_path TO "citus_split_test_schema", public, pg_catalog;
    SET citus.show_shards_for_app_name_prefixes = '*';
    SELECT tbl.relname, fk."Constraint", fk."Definition"
            FROM pg_catalog.pg_class tbl
            JOIN public.table_fkeys fk on tbl.oid = fk.relid
            WHERE tbl.relname like 'sensors_%'
            ORDER BY 1, 2;
     relname     |         Constraint         |                                 Definition
---------------------------------------------------------------------
 sensors_8981013 | fkey_table_to_dist_8981013 | FOREIGN KEY (measureid) REFERENCES colocated_dist_table_8981016(measureid)
 sensors_8981014 | fkey_table_to_dist_8981014 | FOREIGN KEY (measureid) REFERENCES colocated_dist_table_8981017(measureid)
(2 rows)

    SELECT tablename, indexdef FROM pg_indexes WHERE tablename like 'sensors_%' ORDER BY 1,2;
    tablename    |                                                                                                indexdef
---------------------------------------------------------------------
 sensors_8981013 | CREATE INDEX hash_index_on_sensors_8981013 ON citus_split_test_schema.sensors_8981013 USING hash (((measure_data -> 'IsFailed'::text)))
 sensors_8981013 | CREATE INDEX index_on_sensors_8981013 ON citus_split_test_schema.sensors_8981013 USING btree (lower((measureid)::text))
 sensors_8981013 | CREATE INDEX index_with_include_on_sensors_8981013 ON citus_split_test_schema.sensors_8981013 USING btree (((measure_data -> 'IsFailed'::text))) INCLUDE (measure_data, eventdatetime, measure_status)
 sensors_8981013 | CREATE UNIQUE INDEX sensors_pkey_8981013 ON citus_split_test_schema.sensors_8981013 USING btree (measureid, eventdatetime, measure_data)
 sensors_8981014 | CREATE INDEX hash_index_on_sensors_8981014 ON citus_split_test_schema.sensors_8981014 USING hash (((measure_data -> 'IsFailed'::text)))
 sensors_8981014 | CREATE INDEX index_on_sensors_8981014 ON citus_split_test_schema.sensors_8981014 USING btree (lower((measureid)::text))
 sensors_8981014 | CREATE INDEX index_with_include_on_sensors_8981014 ON citus_split_test_schema.sensors_8981014 USING btree (((measure_data -> 'IsFailed'::text))) INCLUDE (measure_data, eventdatetime, measure_status)
 sensors_8981014 | CREATE UNIQUE INDEX sensors_pkey_8981014 ON citus_split_test_schema.sensors_8981014 USING btree (measureid, eventdatetime, measure_data)
(8 rows)

    SELECT tablename, indexdef FROM pg_indexes WHERE tablename like 'table_with_index_rep_identity_%' ORDER BY 1,2;
               tablename               |                                                      indexdef
---------------------------------------------------------------------
 table_with_index_rep_identity_8981019 | CREATE UNIQUE INDEX uqx_8981019 ON citus_split_test_schema.table_with_index_rep_identity_8981019 USING btree (key)
 table_with_index_rep_identity_8981020 | CREATE UNIQUE INDEX uqx_8981020 ON citus_split_test_schema.table_with_index_rep_identity_8981020 USING btree (key)
(2 rows)

    SELECT stxname FROM pg_statistic_ext
    WHERE stxnamespace IN (
        SELECT oid
        FROM pg_namespace
        WHERE nspname IN ('citus_split_test_schema')
    )
    ORDER BY stxname ASC;
         stxname
---------------------------------------------------------------------
 stats_on_sensors
 stats_on_sensors_8981013
 stats_on_sensors_8981014
(3 rows)

\c - - - :worker_2_port
    SET search_path TO "citus_split_test_schema", public, pg_catalog;
    SET citus.show_shards_for_app_name_prefixes = '*';
    SELECT tbl.relname, fk."Constraint", fk."Definition"
            FROM pg_catalog.pg_class tbl
            JOIN public.table_fkeys fk on tbl.oid = fk.relid
            WHERE tbl.relname like 'sensors_%'
            ORDER BY 1, 2;
     relname     |         Constraint         |                                 Definition
---------------------------------------------------------------------
 sensors_8981007 | fkey_table_to_dist_8981007 | FOREIGN KEY (measureid) REFERENCES colocated_dist_table_8981009(measureid)
 sensors_8981008 | fkey_table_to_dist_8981008 | FOREIGN KEY (measureid) REFERENCES colocated_dist_table_8981010(measureid)
 sensors_8981015 | fkey_table_to_dist_8981015 | FOREIGN KEY (measureid) REFERENCES colocated_dist_table_8981018(measureid)
(3 rows)

    SELECT tablename, indexdef FROM pg_indexes WHERE tablename like 'sensors_%' ORDER BY 1,2;
    tablename    |                                                                                                indexdef
---------------------------------------------------------------------
 sensors_8981007 | CREATE INDEX hash_index_on_sensors_8981007 ON citus_split_test_schema.sensors_8981007 USING hash (((measure_data -> 'IsFailed'::text)))
 sensors_8981007 | CREATE INDEX index_on_sensors_8981007 ON citus_split_test_schema.sensors_8981007 USING btree (lower((measureid)::text))
 sensors_8981007 | CREATE INDEX index_with_include_on_sensors_8981007 ON citus_split_test_schema.sensors_8981007 USING btree (((measure_data -> 'IsFailed'::text))) INCLUDE (measure_data, eventdatetime, measure_status)
 sensors_8981007 | CREATE UNIQUE INDEX sensors_pkey_8981007 ON citus_split_test_schema.sensors_8981007 USING btree (measureid, eventdatetime, measure_data)
 sensors_8981008 | CREATE INDEX hash_index_on_sensors_8981008 ON citus_split_test_schema.sensors_8981008 USING hash (((measure_data -> 'IsFailed'::text)))
 sensors_8981008 | CREATE INDEX index_on_sensors_8981008 ON citus_split_test_schema.sensors_8981008 USING btree (lower((measureid)::text))
 sensors_8981008 | CREATE INDEX index_with_include_on_sensors_8981008 ON citus_split_test_schema.sensors_8981008 USING btree (((measure_data -> 'IsFailed'::text))) INCLUDE (measure_data, eventdatetime, measure_status)
 sensors_8981008 | CREATE UNIQUE INDEX sensors_pkey_8981008 ON citus_split_test_schema.sensors_8981008 USING btree (measureid, eventdatetime, measure_data)
 sensors_8981015 | CREATE INDEX hash_index_on_sensors_8981015 ON citus_split_test_schema.sensors_8981015 USING hash (((measure_data -> 'IsFailed'::text)))
 sensors_8981015 | CREATE INDEX index_on_sensors_8981015 ON citus_split_test_schema.sensors_8981015 USING btree (lower((measureid)::text))
 sensors_8981015 | CREATE INDEX index_with_include_on_sensors_8981015 ON citus_split_test_schema.sensors_8981015 USING btree (((measure_data -> 'IsFailed'::text))) INCLUDE (measure_data, eventdatetime, measure_status)
 sensors_8981015 | CREATE UNIQUE INDEX sensors_pkey_8981015 ON citus_split_test_schema.sensors_8981015 USING btree (measureid, eventdatetime, measure_data)
(12 rows)

    SELECT tablename, indexdef FROM pg_indexes WHERE tablename like 'table_with_index_rep_identity_%' ORDER BY 1,2;
               tablename               |                                                      indexdef
---------------------------------------------------------------------
 table_with_index_rep_identity_8981011 | CREATE UNIQUE INDEX uqx_8981011 ON citus_split_test_schema.table_with_index_rep_identity_8981011 USING btree (key)
 table_with_index_rep_identity_8981012 | CREATE UNIQUE INDEX uqx_8981012 ON citus_split_test_schema.table_with_index_rep_identity_8981012 USING btree (key)
 table_with_index_rep_identity_8981021 | CREATE UNIQUE INDEX uqx_8981021 ON citus_split_test_schema.table_with_index_rep_identity_8981021 USING btree (key)
(3 rows)

    SELECT stxname FROM pg_statistic_ext
    WHERE stxnamespace IN (
        SELECT oid
        FROM pg_namespace
        WHERE nspname IN ('citus_split_test_schema')
    )
    ORDER BY stxname ASC;
         stxname
---------------------------------------------------------------------
 stats_on_sensors
 stats_on_sensors_8981007
 stats_on_sensors_8981008
 stats_on_sensors_8981015
(4 rows)

-- END : Display current state
-- BEGIN: Should be able to change/drop constraints
\c - postgres - :master_port
SET ROLE test_shard_split_role;
SET search_path TO "citus_split_test_schema";
ALTER INDEX index_on_sensors RENAME TO index_on_sensors_renamed;
ALTER INDEX index_on_sensors_renamed ALTER COLUMN 1 SET STATISTICS 200;
DROP STATISTICS stats_on_sensors;
DROP INDEX index_on_sensors_renamed;
ALTER TABLE sensors DROP CONSTRAINT fkey_table_to_dist;
-- END: Should be able to change/drop constraints
-- BEGIN: Split second time on another schema
SET search_path TO public;
SET citus.next_shard_id TO 8981031;
SELECT pg_catalog.citus_split_shard_by_split_points(
    8981007,
    ARRAY['-2100000000'],
    ARRAY[:worker_1_node, :worker_2_node],
    'force_logical');
 citus_split_shard_by_split_points
---------------------------------------------------------------------

(1 row)

-- BEGIN: Perform deferred cleanup.
CALL pg_catalog.citus_cleanup_orphaned_resources();
NOTICE:  cleaned up 3 orphaned resources
-- END: Perform deferred cleanup.
SET search_path TO "citus_split_test_schema";
SELECT shard.shardid, logicalrelid, shardminvalue, shardmaxvalue, nodename, nodeport
  FROM pg_dist_shard AS shard
  INNER JOIN pg_dist_placement placement ON shard.shardid = placement.shardid
  INNER JOIN pg_dist_node       node     ON placement.groupid = node.groupid
  INNER JOIN pg_catalog.pg_class cls     ON shard.logicalrelid = cls.oid
  WHERE node.noderole = 'primary' AND (logicalrelid = 'sensors'::regclass OR logicalrelid = 'colocated_dist_table'::regclass OR logicalrelid = 'table_with_index_rep_identity'::regclass)
  ORDER BY logicalrelid, shardminvalue::BIGINT;
 shardid |         logicalrelid          | shardminvalue | shardmaxvalue | nodename  | nodeport
---------------------------------------------------------------------
 8981031 | sensors                       | -2147483648   | -2100000000   | localhost |    57637
 8981032 | sensors                       | -2099999999   | -1073741824   | localhost |    57638
 8981008 | sensors                       | -1073741823   | -1            | localhost |    57638
 8981013 | sensors                       | 0             | 536870911     | localhost |    57637
 8981014 | sensors                       | 536870912     | 1610612735    | localhost |    57637
 8981015 | sensors                       | 1610612736    | 2147483647    | localhost |    57638
 8981033 | colocated_dist_table          | -2147483648   | -2100000000   | localhost |    57637
 8981034 | colocated_dist_table          | -2099999999   | -1073741824   | localhost |    57638
 8981010 | colocated_dist_table          | -1073741823   | -1            | localhost |    57638
 8981016 | colocated_dist_table          | 0             | 536870911     | localhost |    57637
 8981017 | colocated_dist_table          | 536870912     | 1610612735    | localhost |    57637
 8981018 | colocated_dist_table          | 1610612736    | 2147483647    | localhost |    57638
 8981035 | table_with_index_rep_identity | -2147483648   | -2100000000   | localhost |    57637
 8981036 | table_with_index_rep_identity | -2099999999   | -1073741824   | localhost |    57638
 8981012 | table_with_index_rep_identity | -1073741823   | -1            | localhost |    57638
 8981019 | table_with_index_rep_identity | 0             | 536870911     | localhost |    57637
 8981020 | table_with_index_rep_identity | 536870912     | 1610612735    | localhost |    57637
 8981021 | table_with_index_rep_identity | 1610612736    | 2147483647    | localhost |    57638
(18 rows)

-- END: Split second time on another schema
-- BEGIN: Create a co-located table with no replica identity.
CREATE TABLE table_no_rep_id (measureid integer);
SELECT create_distributed_table('table_no_rep_id', 'measureid', colocate_with:='sensors');
 create_distributed_table
---------------------------------------------------------------------

(1 row)

-- END: Create a co-located table with no replica identity.
-- BEGIN: Split a shard with shard_transfer_mode='auto' and with a colocated table with no replica identity
SET citus.next_shard_id TO 8981041;
SELECT pg_catalog.citus_split_shard_by_split_points(
    8981031,
    ARRAY['-2120000000'],
    ARRAY[:worker_1_node, :worker_2_node]);
ERROR:  cannot use logical replication to transfer shards of the relation table_no_rep_id since it doesn't have a REPLICA IDENTITY or PRIMARY KEY
DETAIL:  UPDATE and DELETE commands on the shard will error out during logical replication unless there is a REPLICA IDENTITY or PRIMARY KEY.
HINT:  If you wish to continue without a replica identity set the shard_transfer_mode to 'force_logical' or 'block_writes'.
-- BEGIN: Perform deferred cleanup.
SET client_min_messages TO WARNING;
CALL pg_catalog.citus_cleanup_orphaned_resources();
RESET client_min_messages;
-- END: Perform deferred cleanup.
SELECT shard.shardid, logicalrelid, shardminvalue, shardmaxvalue, nodename, nodeport
  FROM pg_dist_shard AS shard
  INNER JOIN pg_dist_placement placement ON shard.shardid = placement.shardid
  INNER JOIN pg_dist_node       node     ON placement.groupid = node.groupid
  INNER JOIN pg_catalog.pg_class cls     ON shard.logicalrelid = cls.oid
  WHERE node.noderole = 'primary' AND (logicalrelid = 'sensors'::regclass OR logicalrelid = 'colocated_dist_table'::regclass OR logicalrelid = 'table_with_index_rep_identity'::regclass)
  ORDER BY logicalrelid, shardminvalue::BIGINT;
 shardid |         logicalrelid          | shardminvalue | shardmaxvalue | nodename  | nodeport
---------------------------------------------------------------------
 8981031 | sensors                       | -2147483648   | -2100000000   | localhost |    57637
 8981032 | sensors                       | -2099999999   | -1073741824   | localhost |    57638
 8981008 | sensors                       | -1073741823   | -1            | localhost |    57638
 8981013 | sensors                       | 0             | 536870911     | localhost |    57637
 8981014 | sensors                       | 536870912     | 1610612735    | localhost |    57637
 8981015 | sensors                       | 1610612736    | 2147483647    | localhost |    57638
 8981033 | colocated_dist_table          | -2147483648   | -2100000000   | localhost |    57637
 8981034 | colocated_dist_table          | -2099999999   | -1073741824   | localhost |    57638
 8981010 | colocated_dist_table          | -1073741823   | -1            | localhost |    57638
 8981016 | colocated_dist_table          | 0             | 536870911     | localhost |    57637
 8981017 | colocated_dist_table          | 536870912     | 1610612735    | localhost |    57637
 8981018 | colocated_dist_table          | 1610612736    | 2147483647    | localhost |    57638
 8981035 | table_with_index_rep_identity | -2147483648   | -2100000000   | localhost |    57637
 8981036 | table_with_index_rep_identity | -2099999999   | -1073741824   | localhost |    57638
 8981012 | table_with_index_rep_identity | -1073741823   | -1            | localhost |    57638
 8981019 | table_with_index_rep_identity | 0             | 536870911     | localhost |    57637
 8981020 | table_with_index_rep_identity | 536870912     | 1610612735    | localhost |    57637
 8981021 | table_with_index_rep_identity | 1610612736    | 2147483647    | localhost |    57638
(18 rows)

-- END: Split a shard with shard_transfer_mode='auto' and with a colocated table with no replica identity
-- BEGIN: Drop the co-located table with no replica identity.
DROP TABLE table_no_rep_id;
-- END: Drop the co-located table with no replica identity.
-- BEGIN: Split a shard with shard_transfer_mode='auto' and with all colocated tables has replica identity
SET citus.next_shard_id TO 8981041;
SELECT pg_catalog.citus_split_shard_by_split_points(
    8981031,
    ARRAY['-2120000000'],
    ARRAY[:worker_1_node, :worker_2_node],
    'auto');
 citus_split_shard_by_split_points
---------------------------------------------------------------------

(1 row)

-- BEGIN: Perform deferred cleanup.
SET client_min_messages TO WARNING;
CALL pg_catalog.citus_cleanup_orphaned_resources();
RESET client_min_messages;
-- END: Perform deferred cleanup.
SELECT shard.shardid, logicalrelid, shardminvalue, shardmaxvalue, nodename, nodeport
  FROM pg_dist_shard AS shard
  INNER JOIN pg_dist_placement placement ON shard.shardid = placement.shardid
  INNER JOIN pg_dist_node       node     ON placement.groupid = node.groupid
  INNER JOIN pg_catalog.pg_class cls     ON shard.logicalrelid = cls.oid
  WHERE node.noderole = 'primary' AND (logicalrelid = 'sensors'::regclass OR logicalrelid = 'colocated_dist_table'::regclass OR logicalrelid = 'table_with_index_rep_identity'::regclass)
  ORDER BY logicalrelid, shardminvalue::BIGINT;
 shardid |         logicalrelid          | shardminvalue | shardmaxvalue | nodename  | nodeport
---------------------------------------------------------------------
 8981041 | sensors                       | -2147483648   | -2120000000   | localhost |    57637
 8981042 | sensors                       | -2119999999   | -2100000000   | localhost |    57638
 8981032 | sensors                       | -2099999999   | -1073741824   | localhost |    57638
 8981008 | sensors                       | -1073741823   | -1            | localhost |    57638
 8981013 | sensors                       | 0             | 536870911     | localhost |    57637
 8981014 | sensors                       | 536870912     | 1610612735    | localhost |    57637
 8981015 | sensors                       | 1610612736    | 2147483647    | localhost |    57638
 8981043 | colocated_dist_table          | -2147483648   | -2120000000   | localhost |    57637
 8981044 | colocated_dist_table          | -2119999999   | -2100000000   | localhost |    57638
 8981034 | colocated_dist_table          | -2099999999   | -1073741824   | localhost |    57638
 8981010 | colocated_dist_table          | -1073741823   | -1            | localhost |    57638
 8981016 | colocated_dist_table          | 0             | 536870911     | localhost |    57637
 8981017 | colocated_dist_table          | 536870912     | 1610612735    | localhost |    57637
 8981018 | colocated_dist_table          | 1610612736    | 2147483647    | localhost |    57638
 8981045 | table_with_index_rep_identity | -2147483648   | -2120000000   | localhost |    57637
 8981046 | table_with_index_rep_identity | -2119999999   | -2100000000   | localhost |    57638
 8981036 | table_with_index_rep_identity | -2099999999   | -1073741824   | localhost |    57638
 8981012 | table_with_index_rep_identity | -1073741823   | -1            | localhost |    57638
 8981019 | table_with_index_rep_identity | 0             | 536870911     | localhost |    57637
 8981020 | table_with_index_rep_identity | 536870912     | 1610612735    | localhost |    57637
 8981021 | table_with_index_rep_identity | 1610612736    | 2147483647    | localhost |    57638
(21 rows)

-- END: Split a shard with shard_transfer_mode='auto' and with all colocated tables has replica identity
-- BEGIN: Validate Data Count
SELECT COUNT(*) FROM sensors;
 count
---------------------------------------------------------------------
  1001
(1 row)

SELECT COUNT(*) FROM reference_table;
 count
---------------------------------------------------------------------
  1001
(1 row)

SELECT COUNT(*) FROM colocated_dist_table;
 count
---------------------------------------------------------------------
  1001
(1 row)

-- END: Validate Data Count
--BEGIN : Cleanup
\c - postgres - :master_port
-- make sure we don't have any replication objects leftover on the workers
SELECT run_command_on_workers($$SELECT count(*) FROM pg_replication_slots$$);
 run_command_on_workers
---------------------------------------------------------------------
 (localhost,57637,t,0)
 (localhost,57638,t,0)
(2 rows)

SELECT run_command_on_workers($$SELECT count(*) FROM pg_publication$$);
 run_command_on_workers
---------------------------------------------------------------------
 (localhost,57637,t,0)
 (localhost,57638,t,0)
(2 rows)

SELECT run_command_on_workers($$SELECT count(*) FROM pg_subscription$$);
 run_command_on_workers
---------------------------------------------------------------------
 (localhost,57637,t,0)
 (localhost,57638,t,0)
(2 rows)

ALTER SYSTEM RESET citus.defer_shard_delete_interval;
SELECT pg_reload_conf();
 pg_reload_conf
---------------------------------------------------------------------
 t
(1 row)

DROP SCHEMA "citus_split_test_schema" CASCADE;
NOTICE:  drop cascades to 4 other objects
DETAIL:  drop cascades to table citus_split_test_schema.sensors
drop cascades to table citus_split_test_schema.reference_table
drop cascades to table citus_split_test_schema.colocated_dist_table
drop cascades to table citus_split_test_schema.table_with_index_rep_identity
--END : Cleanup
