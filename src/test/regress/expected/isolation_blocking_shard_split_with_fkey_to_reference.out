Parsed test spec with 2 sessions

starting permutation: s2-add-fkey s1-begin s2-begin s2-blocking-shard-split s1-delete s2-commit s1-commit s2-print-cluster
create_distributed_table
---------------------------------------------------------------------

(1 row)

step s2-add-fkey:
 ALTER TABLE table_to_split ADD CONSTRAINT fkey_const FOREIGN KEY(value) REFERENCES reference_table(id);

step s1-begin:
    BEGIN;

step s2-begin:
 BEGIN;

step s2-blocking-shard-split:
 SELECT pg_catalog.citus_split_shard_by_split_points(
  1500002,
  ARRAY['-1073741824'],
  ARRAY[1, 2],
  'block_writes');

citus_split_shard_by_split_points
---------------------------------------------------------------------

(1 row)

step s1-delete:
 DELETE FROM reference_table WHERE id = 5;
 <waiting ...>
step s2-commit: 
 COMMIT;

step s1-delete: <... completed>
step s1-commit:
 COMMIT;

step s2-print-cluster:
 -- row count per shard
 SELECT
  nodeport, shardid, success, result
 FROM
  run_command_on_placements('table_to_split', 'select count(*) from %s')
 ORDER BY
  nodeport, shardid;
 -- rows
 SELECT id, value FROM table_to_split ORDER BY id, value;

nodeport|shardid|success|result
---------------------------------------------------------------------
   57637|1500004|t      |     0
   57638|1500003|t      |     0
   57638|1500005|t      |     0
(3 rows)

id|value
---------------------------------------------------------------------
(0 rows)


starting permutation: s2-add-fkey s1-begin s2-begin s2-blocking-shard-split s1-update s2-commit s1-commit s2-print-cluster
create_distributed_table
---------------------------------------------------------------------

(1 row)

step s2-add-fkey:
 ALTER TABLE table_to_split ADD CONSTRAINT fkey_const FOREIGN KEY(value) REFERENCES reference_table(id);

step s1-begin:
    BEGIN;

step s2-begin:
 BEGIN;

step s2-blocking-shard-split:
 SELECT pg_catalog.citus_split_shard_by_split_points(
  1500002,
  ARRAY['-1073741824'],
  ARRAY[1, 2],
  'block_writes');

citus_split_shard_by_split_points
---------------------------------------------------------------------

(1 row)

step s1-update:
 UPDATE reference_table SET value = 5 WHERE id = 5;
 <waiting ...>
step s2-commit: 
 COMMIT;

step s1-update: <... completed>
step s1-commit:
 COMMIT;

step s2-print-cluster:
 -- row count per shard
 SELECT
  nodeport, shardid, success, result
 FROM
  run_command_on_placements('table_to_split', 'select count(*) from %s')
 ORDER BY
  nodeport, shardid;
 -- rows
 SELECT id, value FROM table_to_split ORDER BY id, value;

nodeport|shardid|success|result
---------------------------------------------------------------------
   57637|1500004|t      |     0
   57638|1500003|t      |     0
   57638|1500005|t      |     0
(3 rows)

id|value
---------------------------------------------------------------------
(0 rows)


starting permutation: s2-add-fkey s1-begin s2-begin s2-blocking-shard-split s1-insert s2-commit s1-commit s2-print-cluster
create_distributed_table
---------------------------------------------------------------------

(1 row)

step s2-add-fkey:
 ALTER TABLE table_to_split ADD CONSTRAINT fkey_const FOREIGN KEY(value) REFERENCES reference_table(id);

step s1-begin:
    BEGIN;

step s2-begin:
 BEGIN;

step s2-blocking-shard-split:
 SELECT pg_catalog.citus_split_shard_by_split_points(
  1500002,
  ARRAY['-1073741824'],
  ARRAY[1, 2],
  'block_writes');

citus_split_shard_by_split_points
---------------------------------------------------------------------

(1 row)

step s1-insert:
 INSERT INTO reference_table VALUES (5, 10);
 <waiting ...>
step s2-commit: 
 COMMIT;

step s1-insert: <... completed>
step s1-commit:
 COMMIT;

step s2-print-cluster:
 -- row count per shard
 SELECT
  nodeport, shardid, success, result
 FROM
  run_command_on_placements('table_to_split', 'select count(*) from %s')
 ORDER BY
  nodeport, shardid;
 -- rows
 SELECT id, value FROM table_to_split ORDER BY id, value;

nodeport|shardid|success|result
---------------------------------------------------------------------
   57637|1500004|t      |     0
   57638|1500003|t      |     0
   57638|1500005|t      |     0
(3 rows)

id|value
---------------------------------------------------------------------
(0 rows)


starting permutation: s2-add-fkey s1-begin s2-begin s2-blocking-shard-split s1-copy s2-commit s1-commit s2-print-cluster
create_distributed_table
---------------------------------------------------------------------

(1 row)

step s2-add-fkey:
 ALTER TABLE table_to_split ADD CONSTRAINT fkey_const FOREIGN KEY(value) REFERENCES reference_table(id);

step s1-begin:
    BEGIN;

step s2-begin:
 BEGIN;

step s2-blocking-shard-split:
 SELECT pg_catalog.citus_split_shard_by_split_points(
  1500002,
  ARRAY['-1073741824'],
  ARRAY[1, 2],
  'block_writes');

citus_split_shard_by_split_points
---------------------------------------------------------------------

(1 row)

step s1-copy:
 COPY reference_table FROM PROGRAM 'echo "1,1\n2,2\n3,3\n4,4\n5,5"' WITH CSV;
 <waiting ...>
step s2-commit: 
 COMMIT;

step s1-copy: <... completed>
step s1-commit:
 COMMIT;

step s2-print-cluster:
 -- row count per shard
 SELECT
  nodeport, shardid, success, result
 FROM
  run_command_on_placements('table_to_split', 'select count(*) from %s')
 ORDER BY
  nodeport, shardid;
 -- rows
 SELECT id, value FROM table_to_split ORDER BY id, value;

nodeport|shardid|success|result
---------------------------------------------------------------------
   57637|1500004|t      |     0
   57638|1500003|t      |     0
   57638|1500005|t      |     0
(3 rows)

id|value
---------------------------------------------------------------------
(0 rows)


starting permutation: s2-add-fkey s1-begin s2-begin s2-blocking-shard-split s1-ddl s2-commit s1-commit s2-print-cluster
create_distributed_table
---------------------------------------------------------------------

(1 row)

step s2-add-fkey:
 ALTER TABLE table_to_split ADD CONSTRAINT fkey_const FOREIGN KEY(value) REFERENCES reference_table(id);

step s1-begin:
    BEGIN;

step s2-begin:
 BEGIN;

step s2-blocking-shard-split:
 SELECT pg_catalog.citus_split_shard_by_split_points(
  1500002,
  ARRAY['-1073741824'],
  ARRAY[1, 2],
  'block_writes');

citus_split_shard_by_split_points
---------------------------------------------------------------------

(1 row)

step s1-ddl:
 CREATE INDEX reference_table_index ON reference_table(id);
 <waiting ...>
step s2-commit: 
 COMMIT;

step s1-ddl: <... completed>
step s1-commit:
 COMMIT;

step s2-print-cluster:
 -- row count per shard
 SELECT
  nodeport, shardid, success, result
 FROM
  run_command_on_placements('table_to_split', 'select count(*) from %s')
 ORDER BY
  nodeport, shardid;
 -- rows
 SELECT id, value FROM table_to_split ORDER BY id, value;

nodeport|shardid|success|result
---------------------------------------------------------------------
   57637|1500004|t      |     0
   57638|1500003|t      |     0
   57638|1500005|t      |     0
(3 rows)

id|value
---------------------------------------------------------------------
(0 rows)

