SET citus.log_remote_commands TO OFF;
DROP SCHEMA IF EXISTS distributed_functions_triggers CASCADE;
NOTICE:  schema "distributed_functions_triggers" does not exist, skipping
CREATE SCHEMA distributed_functions_triggers;
SET search_path TO 'distributed_functions_triggers';
SET citus.shard_replication_factor = 1;
SET citus.shard_count = 32;
SET citus.next_shard_id TO 900000;
CREATE TABLE test_txn_dist(intcol int PRIMARY KEY, data char(50) default 'default');
SELECT create_distributed_table('test_txn_dist', 'intcol', colocate_with := 'none');
 create_distributed_table
---------------------------------------------------------------------

(1 row)

CREATE FUNCTION insert_data(a integer)
RETURNS void LANGUAGE plpgsql AS $fn$
BEGIN
	INSERT INTO distributed_functions_triggers.test_txn_dist VALUES (a);
END;
$fn$;
CREATE FUNCTION insert_data_non_distarg(a integer)
RETURNS void LANGUAGE plpgsql AS $fn$
BEGIN
	INSERT INTO distributed_functions_triggers.test_txn_dist VALUES (a+1);
END;
$fn$;
CREATE FUNCTION update_data_nonlocal(a integer)
RETURNS void LANGUAGE plpgsql AS $fn$
BEGIN
	UPDATE distributed_functions_triggers.test_txn_dist SET data = 'non-default';
END;
$fn$;
SELECT create_distributed_function(
  'insert_data(int)', 'a',
  colocate_with := 'test_txn_dist',
  force_pushdown := true
);
 create_distributed_function
---------------------------------------------------------------------

(1 row)

SELECT create_distributed_function(
  'insert_data_non_distarg(int)', 'a',
  colocate_with := 'test_txn_dist',
  force_pushdown := true
);
 create_distributed_function
---------------------------------------------------------------------

(1 row)

SELECT create_distributed_function(
  'update_data_nonlocal(int)', 'a',
  colocate_with := 'test_txn_dist',
  force_pushdown := true
);
 create_distributed_function
---------------------------------------------------------------------

(1 row)

SET client_min_messages TO DEBUG1;
--SET citus.log_remote_commands TO on;
SELECT public.wait_until_metadata_sync(30000);
 wait_until_metadata_sync
---------------------------------------------------------------------

(1 row)

SELECT 'Transaction with no errors' Testing;
          testing
---------------------------------------------------------------------
 Transaction with no errors
(1 row)

BEGIN;
INSERT INTO distributed_functions_triggers.test_txn_dist VALUES (1);
-- This call will insert both the rows locally on the remote worker
SELECT insert_data(2);
DEBUG:  pushing down function call in a multi-statement transaction
DEBUG:  pushing down the function call
 insert_data
---------------------------------------------------------------------

(1 row)

INSERT INTO distributed_functions_triggers.test_txn_dist VALUES (3);
COMMIT;
SELECT 'Transaction with duplicate error in the remote function' Testing;
                         testing
---------------------------------------------------------------------
 Transaction with duplicate error in the remote function
(1 row)

BEGIN;
INSERT INTO distributed_functions_triggers.test_txn_dist VALUES (4);
-- This call will fail with duplicate error on the remote worker
SELECT insert_data(3);
DEBUG:  pushing down function call in a multi-statement transaction
DEBUG:  pushing down the function call
ERROR:  duplicate key value violates unique constraint "test_txn_dist_pkey_900015"
DETAIL:  Key (intcol)=(3) already exists.
CONTEXT:  SQL statement "INSERT INTO distributed_functions_triggers.test_txn_dist VALUES (a)"
PL/pgSQL function distributed_functions_triggers.insert_data(integer) line XX at SQL statement
while executing command on localhost:xxxxx
INSERT INTO distributed_functions_triggers.test_txn_dist VALUES (5);
ERROR:  current transaction is aborted, commands ignored until end of transaction block
COMMIT;
SELECT 'Transaction with duplicate error in the local statement' Testing;
                         testing
---------------------------------------------------------------------
 Transaction with duplicate error in the local statement
(1 row)

BEGIN;
INSERT INTO distributed_functions_triggers.test_txn_dist VALUES (6);
-- This call will insert both the rows locally on the remote worker
SELECT insert_data(7);
DEBUG:  pushing down function call in a multi-statement transaction
DEBUG:  pushing down the function call
 insert_data
---------------------------------------------------------------------

(1 row)

INSERT INTO distributed_functions_triggers.test_txn_dist VALUES (8);
-- This will fail
INSERT INTO distributed_functions_triggers.test_txn_dist VALUES (8);
ERROR:  duplicate key value violates unique constraint "test_txn_dist_pkey_900000"
DETAIL:  Key (intcol)=(8) already exists.
CONTEXT:  while executing command on localhost:xxxxx
COMMIT;
SELECT 'Transaction with function using non-distribution argument' Testing;
                          testing
---------------------------------------------------------------------
 Transaction with function using non-distribution argument
(1 row)

BEGIN;
-- This should fail
SELECT insert_data_non_distarg(9);
DEBUG:  pushing down function call in a multi-statement transaction
DEBUG:  pushing down the function call
ERROR:  queries must filter by distribution argument when using forced function pushdown
HINT:  consider turning off the flag force_pushdown instead
CONTEXT:  SQL statement "INSERT INTO distributed_functions_triggers.test_txn_dist VALUES (a+1)"
PL/pgSQL function distributed_functions_triggers.insert_data_non_distarg(integer) line XX at SQL statement
while executing command on localhost:xxxxx
COMMIT;
SELECT 'Transaction with function doing remote connection' Testing;
                      testing
---------------------------------------------------------------------
 Transaction with function doing remote connection
(1 row)

BEGIN;
-- This statement will pass
INSERT INTO distributed_functions_triggers.test_txn_dist VALUES (11);
-- This call will try to update rows locally and on a different node
SELECT update_data_nonlocal(12);
DEBUG:  pushing down function call in a multi-statement transaction
DEBUG:  pushing down the function call
ERROR:  queries must filter by distribution argument when using forced function pushdown
HINT:  consider turning off the flag force_pushdown instead
CONTEXT:  SQL statement "UPDATE distributed_functions_triggers.test_txn_dist SET data = 'non-default'"
PL/pgSQL function distributed_functions_triggers.update_data_nonlocal(integer) line XX at SQL statement
while executing command on localhost:xxxxx
INSERT INTO distributed_functions_triggers.test_txn_dist VALUES (13);
ERROR:  current transaction is aborted, commands ignored until end of transaction block
COMMIT;
SELECT 'Transaction with no errors but with a rollback' Testing;
                    testing
---------------------------------------------------------------------
 Transaction with no errors but with a rollback
(1 row)

BEGIN;
INSERT INTO distributed_functions_triggers.test_txn_dist VALUES (14);
-- This call will insert both the rows locally on the remote worker
SELECT insert_data(15);
DEBUG:  pushing down function call in a multi-statement transaction
DEBUG:  pushing down the function call
 insert_data
---------------------------------------------------------------------

(1 row)

INSERT INTO distributed_functions_triggers.test_txn_dist VALUES (16);
ROLLBACK;
--
-- Add function with pushdown=true in the targetList of a query
--
BEGIN;
SELECT insert_data(intcol+17) from test_txn_dist where intcol = 1;
ERROR:  Non-constant arguments for forcePushdown functions not supported
CONTEXT:  while executing command on localhost:xxxxx
SELECT insert_data(18);
ERROR:  current transaction is aborted, commands ignored until end of transaction block
COMMIT;
-- This should have only the first 3 rows as all other transactions were rolled back.
SELECT * FROM distributed_functions_triggers.test_txn_dist ORDER BY 1;
 intcol |                        data
---------------------------------------------------------------------
      1 | default
      2 | default
      3 | default
(3 rows)

--
-- Nested call, function with pushdown=false calling function with pushdown=true
--
CREATE TABLE test_nested (id int, name text);
SELECT create_distributed_table('test_nested','id');
 create_distributed_table
---------------------------------------------------------------------

(1 row)

INSERT INTO test_nested VALUES (100,'hundred');
INSERT INTO test_nested VALUES (200,'twohundred');
INSERT INTO test_nested VALUES (300,'threehundred');
INSERT INTO test_nested VALUES (400,'fourhundred');
CREATE OR REPLACE FUNCTION inner_force_pushdown_function(int)
RETURNS NUMERIC AS $$
DECLARE ret_val NUMERIC;
BEGIN
        SELECT max(id)::numeric+1 INTO ret_val  FROM distributed_functions_triggers.test_nested WHERE id = $1;
	RAISE NOTICE 'inner_force_pushdown_function():%', ret_val;
        RETURN ret_val;
END;
$$  LANGUAGE plpgsql;
CREATE OR REPLACE FUNCTION func_calls_forcepush_func()
RETURNS NUMERIC AS $$
DECLARE incremented_val NUMERIC;
BEGIN
	-- Constant distribution argument
	SELECT inner_force_pushdown_function INTO incremented_val FROM inner_force_pushdown_function(100);
	RETURN incremented_val;
END;
$$  LANGUAGE plpgsql;
SELECT create_distributed_function('func_calls_forcepush_func()');
DEBUG:  switching to sequential query execution mode
DETAIL:  A distributed function is created. To make sure subsequent commands see the type correctly we need to make sure to use only one connection for all future commands
 create_distributed_function
---------------------------------------------------------------------

(1 row)

SELECT create_distributed_function('inner_force_pushdown_function(int)', '$1', colocate_with := 'test_nested', force_pushdown := true);
DEBUG:  switching to sequential query execution mode
DETAIL:  A distributed function is created. To make sure subsequent commands see the type correctly we need to make sure to use only one connection for all future commands
 create_distributed_function
---------------------------------------------------------------------

(1 row)

SELECT public.wait_until_metadata_sync(30000);
 wait_until_metadata_sync
---------------------------------------------------------------------

(1 row)

BEGIN;
SELECT func_calls_forcepush_func();
DEBUG:  not pushing down function calls in a multi-statement transaction
DEBUG:  pushing down function call in a multi-statement transaction
CONTEXT:  SQL statement "SELECT inner_force_pushdown_function                      FROM inner_force_pushdown_function(100)"
PL/pgSQL function func_calls_forcepush_func() line XX at SQL statement
DEBUG:  pushing down the function call
CONTEXT:  SQL statement "SELECT inner_force_pushdown_function                      FROM inner_force_pushdown_function(100)"
PL/pgSQL function func_calls_forcepush_func() line XX at SQL statement
NOTICE:  inner_force_pushdown_function():101
DETAIL:  from localhost:xxxxx
CONTEXT:  SQL statement "SELECT inner_force_pushdown_function                      FROM inner_force_pushdown_function(100)"
PL/pgSQL function func_calls_forcepush_func() line XX at SQL statement
 func_calls_forcepush_func
---------------------------------------------------------------------
                       101
(1 row)

COMMIT;
SELECT func_calls_forcepush_func();
DEBUG:  function does not have co-located tables
NOTICE:  inner_force_pushdown_function():101
DETAIL:  from localhost:xxxxx
CONTEXT:  SQL statement "SELECT inner_force_pushdown_function                      FROM inner_force_pushdown_function(100)"
PL/pgSQL function func_calls_forcepush_func() line XX at SQL statement
 func_calls_forcepush_func
---------------------------------------------------------------------
                       101
(1 row)

CREATE OR REPLACE FUNCTION get_val()
RETURNS INT AS $$
BEGIN
        RETURN 100::INT;
END;
$$  LANGUAGE plpgsql;
--
-- UDF calling another UDF in a FROM clause
-- fn()
-- {
--   select res into var from fn();
-- }
--
CREATE OR REPLACE FUNCTION func_calls_forcepush_func_infrom()
RETURNS NUMERIC AS $$
DECLARE incremented_val NUMERIC;
DECLARE add_val INT;
BEGIN
	add_val := get_val();
	SELECT inner_force_pushdown_function INTO incremented_val FROM inner_force_pushdown_function(add_val + 100);
	RETURN incremented_val;
END;
$$  LANGUAGE plpgsql;
SELECT func_calls_forcepush_func_infrom();
DEBUG:  pushing down function call in a multi-statement transaction
CONTEXT:  SQL statement "SELECT inner_force_pushdown_function                      FROM inner_force_pushdown_function(add_val + 100)"
PL/pgSQL function func_calls_forcepush_func_infrom() line XX at SQL statement
DEBUG:  pushing down the function call
CONTEXT:  SQL statement "SELECT inner_force_pushdown_function                      FROM inner_force_pushdown_function(add_val + 100)"
PL/pgSQL function func_calls_forcepush_func_infrom() line XX at SQL statement
NOTICE:  inner_force_pushdown_function():201
DETAIL:  from localhost:xxxxx
CONTEXT:  SQL statement "SELECT inner_force_pushdown_function                      FROM inner_force_pushdown_function(add_val + 100)"
PL/pgSQL function func_calls_forcepush_func_infrom() line XX at SQL statement
 func_calls_forcepush_func_infrom
---------------------------------------------------------------------
                              201
(1 row)

BEGIN;
SELECT func_calls_forcepush_func_infrom();
DEBUG:  pushing down function call in a multi-statement transaction
CONTEXT:  SQL statement "SELECT inner_force_pushdown_function                      FROM inner_force_pushdown_function(add_val + 100)"
PL/pgSQL function func_calls_forcepush_func_infrom() line XX at SQL statement
DEBUG:  pushing down the function call
CONTEXT:  SQL statement "SELECT inner_force_pushdown_function                      FROM inner_force_pushdown_function(add_val + 100)"
PL/pgSQL function func_calls_forcepush_func_infrom() line XX at SQL statement
NOTICE:  inner_force_pushdown_function():201
DETAIL:  from localhost:xxxxx
CONTEXT:  SQL statement "SELECT inner_force_pushdown_function                      FROM inner_force_pushdown_function(add_val + 100)"
PL/pgSQL function func_calls_forcepush_func_infrom() line XX at SQL statement
 func_calls_forcepush_func_infrom
---------------------------------------------------------------------
                              201
(1 row)

COMMIT;
--
-- UDF calling another UDF in the SELECT targetList
-- fn()
-- {
--   select fn() into var;
-- }
--
CREATE OR REPLACE FUNCTION func_calls_forcepush_func_intarget()
RETURNS NUMERIC AS $$
DECLARE incremented_val NUMERIC;
DECLARE add_val INT;
BEGIN
	add_val := get_val();
	SELECT inner_force_pushdown_function(100 + 100) INTO incremented_val OFFSET 0;
	RETURN incremented_val;
END;
$$  LANGUAGE plpgsql;
SELECT func_calls_forcepush_func_intarget();
DEBUG:  pushing down function call in a multi-statement transaction
CONTEXT:  SQL statement "SELECT inner_force_pushdown_function(100 + 100)                      OFFSET 0"
PL/pgSQL function func_calls_forcepush_func_intarget() line XX at SQL statement
DEBUG:  pushing down the function call
CONTEXT:  SQL statement "SELECT inner_force_pushdown_function(100 + 100)                      OFFSET 0"
PL/pgSQL function func_calls_forcepush_func_intarget() line XX at SQL statement
NOTICE:  inner_force_pushdown_function():201
DETAIL:  from localhost:xxxxx
CONTEXT:  SQL statement "SELECT inner_force_pushdown_function(100 + 100)                      OFFSET 0"
PL/pgSQL function func_calls_forcepush_func_intarget() line XX at SQL statement
 func_calls_forcepush_func_intarget
---------------------------------------------------------------------
                                201
(1 row)

BEGIN;
SELECT func_calls_forcepush_func_intarget();
NOTICE:  inner_force_pushdown_function():201
DETAIL:  from localhost:xxxxx
CONTEXT:  SQL statement "SELECT inner_force_pushdown_function(100 + 100)                      OFFSET 0"
PL/pgSQL function func_calls_forcepush_func_intarget() line XX at SQL statement
 func_calls_forcepush_func_intarget
---------------------------------------------------------------------
                                201
(1 row)

COMMIT;
--
-- Recursive function call with pushdown=true
--
CREATE OR REPLACE FUNCTION test_recursive(inp integer)
RETURNS INT AS $$
DECLARE var INT;
BEGIN
	RAISE NOTICE 'input:%', inp;
	if (inp > 1) then
		inp := inp - 1;
		var := distributed_functions_triggers.test_recursive(inp);
		RETURN var;
	else
		RETURN inp;
	END if;
END;
$$  LANGUAGE plpgsql;
SELECT create_distributed_function('test_recursive(int)', '$1', colocate_with := 'test_nested', force_pushdown := true);
DEBUG:  switching to sequential query execution mode
DETAIL:  A distributed function is created. To make sure subsequent commands see the type correctly we need to make sure to use only one connection for all future commands
 create_distributed_function
---------------------------------------------------------------------

(1 row)

BEGIN;
SELECT test_recursive(5);
DEBUG:  pushing down function call in a multi-statement transaction
DEBUG:  pushing down the function call
NOTICE:  input:5
DETAIL:  from localhost:xxxxx
NOTICE:  input:4
DETAIL:  from localhost:xxxxx
NOTICE:  input:3
DETAIL:  from localhost:xxxxx
NOTICE:  input:2
DETAIL:  from localhost:xxxxx
NOTICE:  input:1
DETAIL:  from localhost:xxxxx
 test_recursive
---------------------------------------------------------------------
              1
(1 row)

END;
--
-- Non constant distribution arguments
--
-- Var node e.g. select fn(col) from table where col=150;
BEGIN;
SELECT inner_force_pushdown_function(id) FROM test_nested WHERE id = 300;
ERROR:  Non-constant arguments for forcePushdown functions not supported
CONTEXT:  while executing command on localhost:xxxxx
END;
-- Param(PARAM_EXEC) node e.g. SELECT fn((SELECT col from test_nested where col=val))
BEGIN;
SELECT inner_force_pushdown_function((SELECT id FROM test_nested WHERE id=400));
ERROR:  Non-constant arguments for forcePushdown functions not supported
CONTEXT:  while executing command on localhost:xxxxx
END;
CREATE TABLE emp (
    empname           text NOT NULL,
    salary            integer
);
CREATE TABLE emp_audit(
    operation         char(1)   NOT NULL,
    stamp             timestamp NOT NULL,
    userid            text      NOT NULL,
    empname           text      NOT NULL,
    salary integer
);
SELECT create_distributed_table('emp','empname');
 create_distributed_table
---------------------------------------------------------------------

(1 row)

SELECT create_distributed_table('emp_audit','empname');
 create_distributed_table
---------------------------------------------------------------------

(1 row)

CREATE OR REPLACE FUNCTION inner_emp(empname text)
RETURNS void
AS $$
DECLARE
BEGIN
    INSERT INTO emp VALUES (empname, 33);
END;
$$ LANGUAGE plpgsql;
CREATE OR REPLACE FUNCTION outer_emp()
RETURNS void
AS $$
DECLARE
BEGIN
    PERFORM inner_emp('hello');
END;
$$ LANGUAGE plpgsql;
SELECT create_distributed_function('inner_emp(text)','empname', force_pushdown := true);
DEBUG:  switching to sequential query execution mode
DETAIL:  A distributed function is created. To make sure subsequent commands see the type correctly we need to make sure to use only one connection for all future commands
 create_distributed_function
---------------------------------------------------------------------

(1 row)

SELECT outer_emp();
DEBUG:  Skipping delegation of function from a PL/PgSQL simple expression
CONTEXT:  SQL statement "SELECT inner_emp('hello')"
PL/pgSQL function outer_emp() line XX at PERFORM
 outer_emp
---------------------------------------------------------------------

(1 row)

SELECT * from emp;
 empname | salary
---------------------------------------------------------------------
 hello   |     33
(1 row)

--
-- Test citus.enable_unsafe_triggers
-- Enables arbitrary triggers on distributed tables
--
/* CDC triggers with monotonically increasing change ID per shard key */
/* table containing all objects (collection) */
CREATE TABLE data (
    shard_key text not null,
    object_id text not null,
    value jsonb not null
);
ALTER TABLE data
ADD CONSTRAINT data_pk
PRIMARY KEY (shard_key, object_id);
DEBUG:  ALTER TABLE / ADD PRIMARY KEY will create implicit index "data_pk" for table "data"
/* table of changes */
CREATE TABLE data_changes (
    shard_key text not null,
    object_id text not null,
    change_id bigint not null,
    change_time timestamptz default now(),
    operation_type text not null,
    new_value jsonb
);
ALTER TABLE data_changes
ADD CONSTRAINT data_changes_pk
PRIMARY KEY (shard_key, object_id, change_id);
DEBUG:  ALTER TABLE / ADD PRIMARY KEY will create implicit index "data_changes_pk" for table "data_changes"
SELECT create_distributed_table('data', 'shard_key');
 create_distributed_table
---------------------------------------------------------------------

(1 row)

SELECT create_distributed_table('data_changes', 'shard_key', colocate_with := 'data');
 create_distributed_table
---------------------------------------------------------------------

(1 row)

SET citus.enable_unsafe_triggers TO true;
SELECT run_command_on_workers('ALTER SYSTEM SET citus.enable_unsafe_triggers TO true;');
       run_command_on_workers
---------------------------------------------------------------------
 (localhost,57637,t,"ALTER SYSTEM")
 (localhost,57638,t,"ALTER SYSTEM")
(2 rows)

SELECT run_command_on_workers('SELECT pg_reload_conf();');
 run_command_on_workers
---------------------------------------------------------------------
 (localhost,57637,t,t)
 (localhost,57638,t,t)
(2 rows)

/* trigger function that is called after any change */
CREATE OR REPLACE FUNCTION record_change()
RETURNS trigger
AS $$
DECLARE
    last_change_id bigint;
BEGIN
    IF (TG_OP = 'DELETE') THEN
      /* get the last change ID for object key in OLD via index(-only) scan */
      SELECT change_id INTO last_change_id
      FROM distributed_functions_triggers.data_changes
      WHERE shard_key = OLD.shard_key AND object_id = OLD.object_id
      ORDER BY change_id DESC LIMIT 1;

      /* insert a change record for the delete */
      INSERT INTO distributed_functions_triggers.data_changes (shard_key, object_id, change_id, operation_type)
      VALUES (OLD.shard_key, OLD.object_id, COALESCE(last_change_id + 1, 1), TG_OP);
    ELSE
      /* get the last change ID for object key in NEW via index(-only) scan */
      SELECT change_id INTO last_change_id
      FROM distributed_functions_triggers.data_changes
      WHERE shard_key = NEW.shard_key AND object_id = NEW.object_id
      ORDER BY change_id DESC LIMIT 1;

      /* insert a change record for the insert/update */
      INSERT INTO distributed_functions_triggers.data_changes (shard_key, object_id, change_id, operation_type, new_value)
      VALUES (NEW.shard_key, NEW.object_id, COALESCE(last_change_id + 1, 1), TG_OP, NEW.value);
    END IF;

    RETURN NULL;
END;
$$ LANGUAGE plpgsql;
CREATE TRIGGER record_change_trigger
AFTER INSERT OR UPDATE OR DELETE ON data
FOR EACH ROW EXECUTE FUNCTION distributed_functions_triggers.record_change();
SELECT public.wait_until_metadata_sync(30000);
 wait_until_metadata_sync
---------------------------------------------------------------------

(1 row)

INSERT INTO data VALUES ('hello','world','{"hello":"world"}');
INSERT INTO data VALUES ('hello2','world2','{"hello2":"world2"}');
DELETE FROM data where shard_key = 'hello';
BEGIN;
UPDATE data SET value = '{}';
END;
--
-- Run bad triggers
--
CREATE FUNCTION insert_document(key text, id text)
RETURNS void LANGUAGE plpgsql AS $fn$
BEGIN
	INSERT INTO distributed_functions_triggers.data VALUES (key, id, '{"id1":"id2"}');
END;
$fn$;
SELECT create_distributed_function(
  'insert_document(text, text)', 'key',
  colocate_with := 'data',
  force_pushdown := true
);
DEBUG:  switching to sequential query execution mode
DETAIL:  A distributed function is created. To make sure subsequent commands see the type correctly we need to make sure to use only one connection for all future commands
 create_distributed_function
---------------------------------------------------------------------

(1 row)

CREATE OR REPLACE FUNCTION bad_shardkey_record_change()
RETURNS trigger
AS $$
DECLARE
    last_change_id bigint;
BEGIN
    INSERT INTO distributed_functions_triggers.data_changes (shard_key, object_id, change_id, operation_type, new_value)
    VALUES ('BAD', NEW.object_id, COALESCE(last_change_id + 1, 1), TG_OP, NEW.value);
    RETURN NULL;
END;
$$ LANGUAGE plpgsql;
CREATE TRIGGER bad_shardkey_record_change_trigger
AFTER INSERT OR UPDATE OR DELETE ON data
FOR EACH ROW EXECUTE FUNCTION distributed_functions_triggers.bad_shardkey_record_change();
SELECT public.wait_until_metadata_sync(30000);
 wait_until_metadata_sync
---------------------------------------------------------------------

(1 row)

SELECT insert_document('hello3', 'world3');
DEBUG:  pushing down the function call
ERROR:  queries must filter by distribution argument when using forced function pushdown
HINT:  consider turning off the flag force_pushdown instead
CONTEXT:  SQL statement "INSERT INTO distributed_functions_triggers.data_changes (shard_key, object_id, change_id, operation_type, new_value)
    VALUES ('BAD', NEW.object_id, COALESCE(last_change_id + 1, 1), TG_OP, NEW.value)"
PL/pgSQL function bad_shardkey_record_change() line XX at SQL statement
SQL statement "INSERT INTO distributed_functions_triggers.data VALUES (key, id, '{"id1":"id2"}')"
PL/pgSQL function insert_document(text,text) line XX at SQL statement
while executing command on localhost:xxxxx
DROP TRIGGER bad_shardkey_record_change_trigger ON data;
CREATE OR REPLACE FUNCTION remote_shardkey_record_change()
RETURNS trigger
AS $$
DECLARE
    last_change_id bigint;
BEGIN
    UPDATE distributed_functions_triggers.data_changes SET operation_type = TG_OP;
    RETURN NULL;
END;
$$ LANGUAGE plpgsql;
CREATE TRIGGER remote_shardkey_record_change_trigger
AFTER INSERT OR UPDATE OR DELETE ON data
FOR EACH ROW EXECUTE FUNCTION distributed_functions_triggers.remote_shardkey_record_change();
SELECT public.wait_until_metadata_sync(30000);
 wait_until_metadata_sync
---------------------------------------------------------------------

(1 row)

BEGIN;
SELECT insert_document('hello4', 'world4');
DEBUG:  pushing down function call in a multi-statement transaction
DEBUG:  pushing down the function call
ERROR:  queries must filter by distribution argument when using forced function pushdown
HINT:  consider turning off the flag force_pushdown instead
CONTEXT:  SQL statement "UPDATE distributed_functions_triggers.data_changes SET operation_type = TG_OP"
PL/pgSQL function remote_shardkey_record_change() line XX at SQL statement
SQL statement "INSERT INTO distributed_functions_triggers.data VALUES (key, id, '{"id1":"id2"}')"
PL/pgSQL function insert_document(text,text) line XX at SQL statement
while executing command on localhost:xxxxx
END;
SELECT insert_document('hello4', 'world4');
DEBUG:  pushing down the function call
ERROR:  queries must filter by distribution argument when using forced function pushdown
HINT:  consider turning off the flag force_pushdown instead
CONTEXT:  SQL statement "UPDATE distributed_functions_triggers.data_changes SET operation_type = TG_OP"
PL/pgSQL function remote_shardkey_record_change() line XX at SQL statement
SQL statement "INSERT INTO distributed_functions_triggers.data VALUES (key, id, '{"id1":"id2"}')"
PL/pgSQL function insert_document(text,text) line XX at SQL statement
while executing command on localhost:xxxxx
SELECT * FROM data;
 shard_key | object_id | value
---------------------------------------------------------------------
 hello2    | world2    | {}
(1 row)

SELECT shard_key, object_id, change_id, operation_type, new_value FROM data_changes ORDER BY change_time;
 shard_key | object_id | change_id | operation_type |      new_value
---------------------------------------------------------------------
 hello     | world     |         1 | INSERT         | {"hello": "world"}
 hello2    | world2    |         1 | INSERT         | {"hello2": "world2"}
 hello     | world     |         2 | DELETE         |
 hello2    | world2    |         2 | UPDATE         | {}
(4 rows)

--
-- Triggers which are not distributed
--
CREATE TABLE emptest (
    empname           text NOT NULL,
    salary            integer
);
CREATE TABLE emptest_audit(
    operation         char(1)   NOT NULL,
    stamp             timestamp NOT NULL,
    userid            text      NOT NULL,
    empname           text      NOT NULL,
    salary integer
);
SELECT create_distributed_table('emptest','empname');
 create_distributed_table
---------------------------------------------------------------------

(1 row)

SELECT create_distributed_table('emptest_audit','empname');
 create_distributed_table
---------------------------------------------------------------------

(1 row)

CREATE OR REPLACE FUNCTION process_emp_audit() RETURNS TRIGGER AS $emp_audit$
    BEGIN
        --
        -- Create a row in emp_audit to reflect the operation performed on emp,
        -- making use of the special variable TG_OP to work out the operation.
        --
        IF (TG_OP = 'DELETE') THEN
            INSERT INTO distributed_functions_triggers.emptest_audit SELECT 'D', now(), user, OLD.*;
        ELSIF (TG_OP = 'UPDATE') THEN
            INSERT INTO distributed_functions_triggers.emptest_audit SELECT 'U', now(), user, NEW.*;
        ELSIF (TG_OP = 'INSERT') THEN
            INSERT INTO distributed_functions_triggers.emptest_audit SELECT 'I', now(), user, NEW.*;
        END IF;
        RETURN NULL; -- result is ignored since this is an AFTER trigger
    END;
$emp_audit$ LANGUAGE plpgsql;
CREATE TRIGGER emptest_audit
AFTER INSERT OR UPDATE OR DELETE ON emptest
    FOR EACH ROW EXECUTE FUNCTION distributed_functions_triggers.process_emp_audit();
INSERT INTO emptest VALUES ('test', 1);
SELECT operation, userid, empname, salary FROM emptest_audit;
 operation |  userid  | empname | salary
---------------------------------------------------------------------
 I         | postgres | test    |      1
(1 row)

DELETE from emptest;
SELECT operation, userid, empname, salary FROM emptest_audit;
 operation |  userid  | empname | salary
---------------------------------------------------------------------
 I         | postgres | test    |      1
 D         | postgres | test    |      1
(2 rows)

RESET client_min_messages;
SET citus.enable_unsafe_triggers TO false;
SET citus.log_remote_commands TO off;
DROP SCHEMA distributed_functions_triggers CASCADE;
NOTICE:  drop cascades to 24 other objects
DETAIL:  drop cascades to table test_txn_dist
drop cascades to function insert_data(integer)
drop cascades to function insert_data_non_distarg(integer)
drop cascades to function update_data_nonlocal(integer)
drop cascades to table test_nested
drop cascades to function inner_force_pushdown_function(integer)
drop cascades to function func_calls_forcepush_func()
drop cascades to function get_val()
drop cascades to function func_calls_forcepush_func_infrom()
drop cascades to function func_calls_forcepush_func_intarget()
drop cascades to function test_recursive(integer)
drop cascades to table emp
drop cascades to table emp_audit
drop cascades to function inner_emp(text)
drop cascades to function outer_emp()
drop cascades to table data
drop cascades to table data_changes
drop cascades to function record_change()
drop cascades to function insert_document(text,text)
drop cascades to function bad_shardkey_record_change()
drop cascades to function remote_shardkey_record_change()
drop cascades to table emptest
drop cascades to table emptest_audit
drop cascades to function process_emp_audit()
